{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_FP-5-7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0KHhdljls2jv",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import gzip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8koJOznOWvIq",
        "colab_type": "code",
        "outputId": "c50df494-ead0-42a6-82f6-d009b0d79e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LZjNADAjs2jz",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/dl-ims/test_subjects','rb') as f:\n",
        "               images = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntuCGkPPUGZi",
        "colab_type": "text"
      },
      "source": [
        "#### Subject IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcxNfjWzUGZj",
        "colab_type": "code",
        "outputId": "f5898483-f11b-433b-923c-ca45f081d94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "im_name_list =[]\n",
        "\n",
        "for x1 in images:\n",
        "    im_name_list.append(x1)\n",
        "im_name_list"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OAS30001',\n",
              " 'OAS30002',\n",
              " 'OAS30004',\n",
              " 'OAS30005',\n",
              " 'OAS30006',\n",
              " 'OAS30007',\n",
              " 'OAS30008',\n",
              " 'OAS30019',\n",
              " 'OAS30022',\n",
              " 'OAS30024',\n",
              " 'OAS30027']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U3-dxk-UGZl",
        "colab_type": "text"
      },
      "source": [
        "#### Making training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kE0NS3tUGZm",
        "colab_type": "code",
        "outputId": "a9fd98b6-1f30-404e-b73a-5b60e0be2a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pixels=np.zeros((1, 120, 160, 120))\n",
        "for name in im_name_list:\n",
        "    pixels= np.append(pixels ,np.reshape(images[name]['image'], (1, 120, 160, 120) ), axis=0)\n",
        "\n",
        "input_ims= pixels[1:12,:,:,:] \n",
        "input_ims.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 120, 160, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckcVU8vdoBfc",
        "colab_type": "text"
      },
      "source": [
        "#dont"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ABCrDBn_0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c36b087-3900-457a-da17-2764b645405e"
      },
      "source": [
        "x_train = input_ims[2:12,:,:,:]\n",
        "x_train.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 120, 160, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr3eydIloFKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e874664f-4926-4423-9868-2ed8021826ef"
      },
      "source": [
        "x_test=input_ims[0:2,:,:,:]\n",
        "x_test.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 120, 160, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZbAzLKhoG9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test= np.reshape(x_test, (2, 120, 160, 120, 1) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRtqcSfxoDiH",
        "colab_type": "text"
      },
      "source": [
        "do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2rMKeiKUGZo",
        "colab_type": "code",
        "outputId": "5e475829-edd8-4041-8d28-29a7ba5f9424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = input_ims[0:9,:,:,:]\n",
        "x_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 120, 160, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRiDq0aEUGZr",
        "colab_type": "code",
        "outputId": "fdeb95f6-f601-4b70-c050-49a2693ddb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test=input_ims[9:12,:,:,:]\n",
        "x_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 120, 160, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2dqArmV00R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test= np.reshape(x_test, (2, 120, 160, 120, 1) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Ko9vksUGZu",
        "colab_type": "text"
      },
      "source": [
        "#### Making target values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-2WgXfGhziD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train= [images[key]['group'] for key in images.keys()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJIbKq4mUGZu",
        "colab_type": "code",
        "outputId": "4f810e59-8b0f-4905-b41a-6287e3ca8636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "y_test = y_train[-2:]\n",
        "y_test"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AD', 'AD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JMDvjDIUGZx",
        "colab_type": "code",
        "outputId": "21080def-b607-44c8-fa05-719b5b8c7b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = y_train[:9]\n",
        "y_train"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CN', 'CN', 'CN', 'CN', 'CN', 'CN', 'CN', 'AD', 'AD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvH5WXTrUGZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_numeric(x):\n",
        "    if x == \"AD\":\n",
        "        return 1\n",
        "    elif x == \"CN\":\n",
        "        return 0\n",
        "    else:\n",
        "        return x\n",
        "    \n",
        "    \n",
        "y_train = list(map( convert_numeric, y_train))\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTEBBiJ2UGZ1",
        "colab_type": "code",
        "outputId": "dd38cda6-f116-400c-b1d2-d163cd63f4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test = list(map( convert_numeric, y_test))\n",
        "y_test"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-EM0OscUGZ3",
        "colab_type": "code",
        "outputId": "74a9d1db-bbf8-4392-d858-51d980e88faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(input_ims)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg183FUvUGZ6",
        "colab_type": "code",
        "outputId": "f896d862-a945-4cbf-b37f-8ca0293141ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#looking into first image\n",
        "first_im=images['OAS30001']\n",
        "first = first_im['image']\n",
        "first.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 160, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCGQTwSoUGZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_modified= np.reshape(first, (120, 160, 120 , 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBpkRIRDyCZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.reshape(x_train, (9, 120, 160, 120, 1) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkHCiPyJb3n-",
        "colab_type": "text"
      },
      "source": [
        "###To categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PuZnrHFb6fE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c466e079-9dbd-4a3e-d83a-f5804972a93c"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "y_train= [images[key]['group'] for key in images.keys()]\n",
        "y_train"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CN', 'CN', 'CN', 'CN', 'CN', 'CN', 'CN', 'AD', 'AD', 'AD', 'AD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anS725VEc1OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_codes= [\"CN\", \"AD\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlx2FT20dp1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_codes = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCet-RyOdA4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_series = pd.Series(y_codes, dtype=\"category\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiNisiC5dFBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "abc9d5d0-6698-4a08-a426-9e0c2308d43d"
      },
      "source": [
        "y_series.cat.codes"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     1\n",
              "1     1\n",
              "2     1\n",
              "3     1\n",
              "4     1\n",
              "5     1\n",
              "6     1\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "dtype: int8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6bnjKdgdUIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_nums = np.array([0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANoC7ZvPdZc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prep = to_categorical(y_series.cat.codes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3U67WOAdfKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ab39ac3a-a98c-45e3-bb2c-8a432f46bd5c"
      },
      "source": [
        "y_prep"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcVskoNZpYvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_prep[-9:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpkejSnGphjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "720cba97-bccd-4ae3-ff74-7aebf9395d33"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8IWPiKUpaJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = y_prep[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5J5bcrcpkKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57023e93-feae-40cd-f0e1-38f157bc9a09"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OXsowSxo_Ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c388efe6-87d6-4338-d458-df6e1193f6dc"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CN', 'CN', 'CN', 'CN', 'CN', 'CN', 'CN', 'AD', 'AD', 'AD', 'AD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgjOJFc6eYap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_prep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlzEfRKjebfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47e78409-5bfb-4875-fc33-23145d5edf7e"
      },
      "source": [
        "y_train = y_train[-9:]\n",
        "y_train"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CN', 'CN', 'CN', 'CN', 'CN', 'AD', 'AD', 'AD', 'AD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsgEM6Wxen2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ff05fff-4e7e-4b73-b5e3-552252a5781a"
      },
      "source": [
        "y_test = y_train[:2]\n",
        "y_test"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CN', 'CN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y699oIkscZtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9bc83f8f-674b-4fed-9b03-419a544278bc"
      },
      "source": [
        "cat = to_categorical(y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e0c52ee4de2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'CN'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8kJ3DGfpK3T",
        "colab_type": "text"
      },
      "source": [
        "#### Building Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qmchbbyhHXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0f6c088-e3e7-4215-a438-74a1d1dac4a6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv3D, MaxPool3D, Dropout, Flatten, Conv3DTranspose, UpSampling3D, Reshape\n",
        "from keras.layers import Input\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNAqMSGOnNBd",
        "colab_type": "code",
        "outputId": "4b09c1c9-09df-41c3-a20f-d26a9806ac57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv3D, MaxPool3D, Dropout, Flatten, Conv3DTranspose, UpSampling3D, Reshape\n",
        "from keras.layers import Input\n",
        "\n",
        "\n",
        "input_img = Input(shape= (120, 160, 120 , 1))\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "encoded_shape = K.int_shape(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(32, activation='selu')(x)\n",
        "x= Dense(16, activation='selu')(x)\n",
        "encoded = Dense(2, activation='selu')(x)\n",
        "\n",
        "\n",
        "encoder=Model(input_img, encoded, name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 120, 160, 120, 10) 280       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 45000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1440032   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,446,294\n",
            "Trainable params: 1,446,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifbTxu4r7oW",
        "colab_type": "text"
      },
      "source": [
        "#### Building decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpOjuZZGsFUc",
        "colab_type": "code",
        "outputId": "22c54c16-4aaa-4532-f987-344e5c26f7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "encoded_input= Input(shape=(2,))\n",
        "x = Dense(16, activation='selu')(encoded_input)\n",
        "x= Dense(32, activation='selu')(x)\n",
        "x= Dense(np.prod(encoded_shape[1:]))(x)\n",
        "x= Reshape((encoded_shape[1], encoded_shape[2], encoded_shape[3], encoded_shape[4]))(x)\n",
        "\n",
        "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "decoder = Model(encoded_input, x, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                48        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 45000)             1485000   \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_1 (Conv3DTr (None, 15, 20, 15, 10)    2710      \n",
            "_________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_2 (Conv3DTr (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "up_sampling3d_2 (UpSampling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_3 (Conv3DTr (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "up_sampling3d_3 (UpSampling3 (None, 120, 160, 120, 10) 0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 120, 160, 120, 10) 0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_4 (Conv3DTr (None, 120, 160, 120, 1)  271       \n",
            "=================================================================\n",
            "Total params: 1,493,993\n",
            "Trainable params: 1,493,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTCOKfGfwTtB",
        "colab_type": "text"
      },
      "source": [
        "#### Building Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQiTACIywYZS",
        "colab_type": "code",
        "outputId": "ce83682c-9a92-459f-f18e-b16745ff02bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "autoencoder= Model(input_img, decoder(encoder(input_img)), name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 2)                 1446294   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 120, 160, 120, 1)  1493993   \n",
            "=================================================================\n",
            "Total params: 2,940,287\n",
            "Trainable params: 2,940,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pxqUvTspxOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czyHPguCxP_c",
        "colab_type": "code",
        "outputId": "f3da341d-deca-4196-885a-edd11bcf8126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "hist= autoencoder.fit(x_train, x_train, batch_size=3, epochs=200, verbose=1, validation_data=(x_test, x_test))\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9 samples, validate on 2 samples\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 2s 229ms/step - loss: 0.3388 - val_loss: 0.3262\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3393 - val_loss: 0.3266\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3391 - val_loss: 0.3312\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 1s 162ms/step - loss: 0.3385 - val_loss: 0.3267\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3379 - val_loss: 0.3269\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3381 - val_loss: 0.3267\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3381 - val_loss: 0.3315\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3377 - val_loss: 0.3270\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3377 - val_loss: 0.3252\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.3372 - val_loss: 0.3289\n",
            "Epoch 11/200\n",
            "6/9 [===================>..........] - ETA: 0s - loss: 0.3391"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-8b9125aa1a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR0a2kUAgyWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "bcb5c25d-c457-4c02-f137-e6db2d9e2ad3"
      },
      "source": [
        "# Creates a graph.\n",
        "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "c = tf.matmul(a, b)\n",
        " # Creates a session with log_device_placement set to True.\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(sess.run(c))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-85ad614bb31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;31m# Creates a session with log_device_placement set to True.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Runs the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK0LbSEAhL0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "cc11bd4f-762e-45e7-81fa-66919ef5b3d2"
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bf/c28971266ca854a64f4b26f07c4112ddd61f30b4d1f18108b954a746f8ea/tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     || 516.2MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIJmzYK4glhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee0e7d94-66dd-4d0d-c6fc-12799f7a9fa8"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFyUI2jQgOD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "54aab188-3e67-48a2-a15b-23a36391d892"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwnqTNfRVUvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "d9194dff-8263-4ca4-ad85-ddee435c7e56"
      },
      "source": [
        "plt.plot(hist.history['val_loss'], 'r', hist.history['loss'], 'b')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4a40b67f98>,\n",
              " <matplotlib.lines.Line2D at 0x7f4a40b780f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O13nQw1nXMt0",
        "colab_type": "text"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8hJzdTXOq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns8woOfcXQ_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#just to save the model. Don't run again\n",
        "autoencoder.save('cae_selu.h5')\n",
        "model_file = drive.CreateFile({'title' : 'cae_selu.h5'})                       \n",
        "model_file.SetContentFile('cae_selu.h5')                       \n",
        "model_file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSddkcHLXf2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c569cbf0-09d0-47a0-f669-6f7d28693803"
      },
      "source": [
        "# Don't run again. download to google drive                       \n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1-uSIawIVhJCcUpFTRgQ7lXCpk9F6PlS6'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65dEdSXXli6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "d3058d3d-522f-46bd-c28e-c74574b63a60"
      },
      "source": [
        "#Loading models from Google Drive into Colab, Don't run\n",
        "\n",
        "file_obj = drive.CreateFile({'id': '1-uSIawIVhJCcUpFTRgQ7lXCpk9F6PlS6'})                       \n",
        "file_obj.GetContentFile('cae_selu.h5')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-304a0964c376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1-uSIawIVhJCcUpFTRgQ7lXCpk9F6PlS6'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfile_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cae_selu.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentFile\u001b[0;34m(self, filename, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchContent\u001b[0;34m(self, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mexport_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exportLinks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DownloadFromUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_Http_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_DownloadFromUrl\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mApiRequestError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mApiRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot download file: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mnew_request\u001b[0;34m(uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m         resp, content = request(orig_request_method, uri, method, body,\n\u001b[1;32m    174\u001b[0m                                 \u001b[0mclean_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                                 redirections, connection_type)\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# A stored token may expire between the time it is retrieved and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(http, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    280\u001b[0m     return http_callable(uri, method=method, body=body, headers=headers,\n\u001b[1;32m    281\u001b[0m                          \u001b[0mredirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                          connection_type=connection_type)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1989\u001b[0m                         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m                         \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m                         \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m                     )\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m         (response, content) = self._conn_request(\n\u001b[0;32m-> 1651\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m         )\n\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwyUXfTbXwas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "cae_selu=load_model('/content/drive/My Drive/cae_selu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9NXSN-HXzGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "870598de-96c8-4e7f-c236-82a578d73040"
      },
      "source": [
        "cae_selu.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 2)                 1446294   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 120, 160, 120, 1)  1493993   \n",
            "=================================================================\n",
            "Total params: 2,940,287\n",
            "Trainable params: 2,940,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxv33QAeYAQx",
        "colab_type": "text"
      },
      "source": [
        "### Fixing bottleneck nodes and making classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4bjxQoYmZu",
        "colab_type": "text"
      },
      "source": [
        "### Building Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxBGycFHYor-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "8e9d998c-ffc3-4d9b-f04c-e1803e6b7f52"
      },
      "source": [
        "\n",
        "input_img = Input(shape= (120, 160, 120 , 1))\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "encoded_shape = K.int_shape(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(32, activation='selu')(x)\n",
        "encoded = Dense(16, activation='selu')(x)\n",
        "#encoded = Dense(2, activation='selu')(x)\n",
        "\n",
        "\n",
        "encoder_b=Model(input_img, encoded, name='encoder_b')\n",
        "encoder_b.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_b\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "conv3d_8 (Conv3D)            (None, 120, 160, 120, 10) 280       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_7 (MaxPooling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_9 (Conv3D)            (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_8 (MaxPooling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_10 (Conv3D)           (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_9 (MaxPooling3 (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 45000)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                1440032   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 16)                528       \n",
            "=================================================================\n",
            "Total params: 1,446,260\n",
            "Trainable params: 1,446,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEZTo7RAY8sM",
        "colab_type": "text"
      },
      "source": [
        "### Building Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcNya4hoY_nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "de7af44b-4604-4d7c-e3aa-5546d76ff726"
      },
      "source": [
        "encoded_input= Input(shape=(16,))\n",
        "#x = Dense(16, activation='selu')(encoded_input)\n",
        "x= Dense(32, activation='selu')(encoded_input)\n",
        "x= Dense(np.prod(encoded_shape[1:]))(x)\n",
        "x= Reshape((encoded_shape[1], encoded_shape[2], encoded_shape[3], encoded_shape[4]))(x)\n",
        "\n",
        "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = UpSampling3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "decoder_b = Model(encoded_input, x, name='decoder_b')\n",
        "decoder_b.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder_b\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 45000)             1485000   \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_9 (Conv3DTr (None, 15, 20, 15, 10)    2710      \n",
            "_________________________________________________________________\n",
            "up_sampling3d_7 (UpSampling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_10 (Conv3DT (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "up_sampling3d_8 (UpSampling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_11 (Conv3DT (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "up_sampling3d_9 (UpSampling3 (None, 120, 160, 120, 10) 0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 120, 160, 120, 10) 0         \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_12 (Conv3DT (None, 120, 160, 120, 1)  271       \n",
            "=================================================================\n",
            "Total params: 1,493,945\n",
            "Trainable params: 1,493,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U94Eue-VZOKp",
        "colab_type": "text"
      },
      "source": [
        "####Building AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFhbUlm0ZDUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fedd779f-65a5-48a0-e1e3-55850436c147"
      },
      "source": [
        "ae_b= Model(input_img, decoder_b(encoder_b(input_img)), name='autoencoder_b')\n",
        "ae_b.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder_b\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "encoder_b (Model)            (None, 16)                1446260   \n",
            "_________________________________________________________________\n",
            "decoder_b (Model)            (None, 120, 160, 120, 1)  1493945   \n",
            "=================================================================\n",
            "Total params: 2,940,205\n",
            "Trainable params: 2,940,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe4WLSEeZakE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02687727-9186-4b2d-cdd3-557850c1eda3"
      },
      "source": [
        "ae_b.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "hist_b= ae_b.fit(x_train, x_train, epochs=200, verbose=1, validation_data=(x_test, x_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9 samples, validate on 2 samples\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 2s 184ms/step - loss: 0.7019 - val_loss: 0.6927\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.6946 - val_loss: 0.6895\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.6813 - val_loss: 0.6852\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.6629 - val_loss: 0.6789\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.6358 - val_loss: 0.6692\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.6073 - val_loss: 0.6576\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.5795 - val_loss: 0.6471\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.5525 - val_loss: 0.6356\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.5276 - val_loss: 0.6194\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.5055 - val_loss: 0.6051\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.4850 - val_loss: 0.5937\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.4677 - val_loss: 0.5839\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.4513 - val_loss: 0.5754\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.4381 - val_loss: 0.5698\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.4262 - val_loss: 0.5684\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.4158 - val_loss: 0.5671\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.4073 - val_loss: 0.5661\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.4002 - val_loss: 0.5676\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.3938 - val_loss: 0.5661\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.3885 - val_loss: 0.5630\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.3845 - val_loss: 0.5599\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3806 - val_loss: 0.5559\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.3773 - val_loss: 0.5519\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.3749 - val_loss: 0.5476\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3722 - val_loss: 0.5420\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3705 - val_loss: 0.5345\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3686 - val_loss: 0.5295\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3672 - val_loss: 0.5216\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3658 - val_loss: 0.5170\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3645 - val_loss: 0.5139\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3637 - val_loss: 0.5071\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3624 - val_loss: 0.5028\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3616 - val_loss: 0.5011\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3604 - val_loss: 0.4949\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3596 - val_loss: 0.4904\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3589 - val_loss: 0.4873\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3585 - val_loss: 0.4841\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3578 - val_loss: 0.4782\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3608 - val_loss: 0.4824\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3574 - val_loss: 0.4813\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3573 - val_loss: 0.4760\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3563 - val_loss: 0.4749\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3567 - val_loss: 0.4790\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3550 - val_loss: 0.4829\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3558 - val_loss: 0.4820\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3543 - val_loss: 0.4808\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3542 - val_loss: 0.4821\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3543 - val_loss: 0.4859\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3534 - val_loss: 0.4886\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3532 - val_loss: 0.4906\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3528 - val_loss: 0.4904\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3528 - val_loss: 0.4912\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3529 - val_loss: 0.4962\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3523 - val_loss: 0.4976\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3518 - val_loss: 0.4969\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3515 - val_loss: 0.4979\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3514 - val_loss: 0.4992\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3508 - val_loss: 0.5023\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3504 - val_loss: 0.5045\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3505 - val_loss: 0.5042\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3500 - val_loss: 0.5028\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3504 - val_loss: 0.5047\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3498 - val_loss: 0.5048\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3496 - val_loss: 0.5022\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3490 - val_loss: 0.5007\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3500 - val_loss: 0.5037\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3491 - val_loss: 0.5063\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3489 - val_loss: 0.5046\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3489 - val_loss: 0.5002\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3497 - val_loss: 0.5035\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3481 - val_loss: 0.5074\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3484 - val_loss: 0.5061\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3481 - val_loss: 0.5013\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3479 - val_loss: 0.5010\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3483 - val_loss: 0.5065\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3476 - val_loss: 0.5092\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3481 - val_loss: 0.5052\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3470 - val_loss: 0.5010\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3472 - val_loss: 0.5006\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3470 - val_loss: 0.5036\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3468 - val_loss: 0.5053\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3471 - val_loss: 0.5025\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3464 - val_loss: 0.4992\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3469 - val_loss: 0.5015\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3461 - val_loss: 0.5057\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3470 - val_loss: 0.5024\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3460 - val_loss: 0.4992\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3466 - val_loss: 0.5016\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3457 - val_loss: 0.5058\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3460 - val_loss: 0.5049\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3454 - val_loss: 0.5023\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3455 - val_loss: 0.5021\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3455 - val_loss: 0.5041\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3451 - val_loss: 0.5041\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3453 - val_loss: 0.5027\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3446 - val_loss: 0.5015\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3448 - val_loss: 0.5011\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3444 - val_loss: 0.5021\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3446 - val_loss: 0.5016\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3443 - val_loss: 0.5016\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3441 - val_loss: 0.5014\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3441 - val_loss: 0.5027\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3440 - val_loss: 0.5013\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3441 - val_loss: 0.4996\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3439 - val_loss: 0.5004\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3437 - val_loss: 0.5024\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3439 - val_loss: 0.5012\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3436 - val_loss: 0.4993\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3436 - val_loss: 0.5012\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3435 - val_loss: 0.5028\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3439 - val_loss: 0.5015\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3432 - val_loss: 0.5005\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.3436 - val_loss: 0.5015\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3432 - val_loss: 0.5025\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3429 - val_loss: 0.5013\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3430 - val_loss: 0.4990\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3428 - val_loss: 0.4996\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3427 - val_loss: 0.5005\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3425 - val_loss: 0.5017\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3426 - val_loss: 0.4991\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3423 - val_loss: 0.4977\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3425 - val_loss: 0.5005\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3422 - val_loss: 0.5039\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3423 - val_loss: 0.5010\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3422 - val_loss: 0.4976\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3422 - val_loss: 0.4984\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3418 - val_loss: 0.5015\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3420 - val_loss: 0.5025\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3420 - val_loss: 0.4985\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3417 - val_loss: 0.4940\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3423 - val_loss: 0.4974\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3413 - val_loss: 0.5008\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3417 - val_loss: 0.4995\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3416 - val_loss: 0.4937\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3419 - val_loss: 0.4945\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3414 - val_loss: 0.4982\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3413 - val_loss: 0.4999\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3414 - val_loss: 0.4976\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3410 - val_loss: 0.4935\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3417 - val_loss: 0.4966\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3408 - val_loss: 0.4983\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3412 - val_loss: 0.4971\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3408 - val_loss: 0.4923\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3406 - val_loss: 0.4917\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3411 - val_loss: 0.4972\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3408 - val_loss: 0.4988\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3408 - val_loss: 0.4959\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3404 - val_loss: 0.4906\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3409 - val_loss: 0.4901\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3408 - val_loss: 0.4942\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3404 - val_loss: 0.4964\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3408 - val_loss: 0.4933\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3404 - val_loss: 0.4875\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3402 - val_loss: 0.4865\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3407 - val_loss: 0.4917\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3402 - val_loss: 0.4935\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3401 - val_loss: 0.4910\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3399 - val_loss: 0.4863\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3399 - val_loss: 0.4836\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3401 - val_loss: 0.4872\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3396 - val_loss: 0.4923\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3400 - val_loss: 0.4913\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3400 - val_loss: 0.4870\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3396 - val_loss: 0.4855\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3395 - val_loss: 0.4844\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3396 - val_loss: 0.4871\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3395 - val_loss: 0.4884\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3396 - val_loss: 0.4860\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3393 - val_loss: 0.4828\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3394 - val_loss: 0.4846\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3390 - val_loss: 0.4857\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3390 - val_loss: 0.4844\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3391 - val_loss: 0.4828\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3388 - val_loss: 0.4814\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3392 - val_loss: 0.4827\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3390 - val_loss: 0.4826\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3388 - val_loss: 0.4812\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.3388 - val_loss: 0.4794\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3390 - val_loss: 0.4803\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3387 - val_loss: 0.4826\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3387 - val_loss: 0.4821\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3387 - val_loss: 0.4816\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3385 - val_loss: 0.4793\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3385 - val_loss: 0.4792\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3385 - val_loss: 0.4808\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3387 - val_loss: 0.4827\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3386 - val_loss: 0.4780\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3382 - val_loss: 0.4755\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3385 - val_loss: 0.4766\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3381 - val_loss: 0.4758\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3382 - val_loss: 0.4746\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3382 - val_loss: 0.4763\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3381 - val_loss: 0.4767\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3379 - val_loss: 0.4742\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3383 - val_loss: 0.4712\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3383 - val_loss: 0.4727\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3377 - val_loss: 0.4731\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3379 - val_loss: 0.4718\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.3379 - val_loss: 0.4714\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.3377 - val_loss: 0.4714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVhCZrleajMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "838016e9-5f25-4c1c-ac8f-13d7251bb884"
      },
      "source": [
        "plt.plot(hist_b.history['val_loss'], 'r', hist_b.history['loss'], 'b')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6a91f411d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f6a91f412e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2OCR5PTamTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#just to save the model. Don't run again\n",
        "autoencoder.save('cae_16_bn.h5')\n",
        "model_file = drive.CreateFile({'title' : 'cae_16_bn.h5'})                       \n",
        "model_file.SetContentFile('cae_16_bn.h5')                       \n",
        "model_file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlCY_KRya-y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f7e3859-bc57-4d25-a742-8a479890cd93"
      },
      "source": [
        "# Don't run again. download to google drive                       \n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1w3bqlhIEHmMWIUsu2Pg-oXA-n9xj5sq5'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cM2cLuwbBPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading models from Google Drive into Colab, Don't run\n",
        "\n",
        "file_obj = drive.CreateFile({'id': '1w3bqlhIEHmMWIUsu2Pg-oXA-n9xj5sq5'})                       \n",
        "file_obj.GetContentFile('cae_16_bn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ElbNGZbNTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cae_16_bn=load_model('/content/drive/My Drive/cae_16_bn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjqtFyvdbUX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d32711f6-e0e9-4929-dcd0-3d74394b6eda"
      },
      "source": [
        "cae_16_bn.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 2)                 1446294   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 120, 160, 120, 1)  1493993   \n",
            "=================================================================\n",
            "Total params: 2,940,287\n",
            "Trainable params: 2,940,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlwLSE72cD2u",
        "colab_type": "text"
      },
      "source": [
        "###Building Classifier from 2 nodes bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRSY3tYhcIxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ff22716e-cfa4-4c5f-ca95-70a12c80f5c8"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 2)                 1446294   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 120, 160, 120, 1)  1493993   \n",
            "=================================================================\n",
            "Total params: 2,940,287\n",
            "Trainable params: 2,940,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM7_GqqLcqPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LJCxSXKjd9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_c = autoencoder.layers[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxFeZy1DjY-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "1f12cb81-42f4-46b8-9e9f-1912eb2f1292"
      },
      "source": [
        "encoder_c.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 120, 160, 120, 10) 280       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 45000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1440032   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,446,294\n",
            "Trainable params: 1,446,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAxfteEEm8ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccb6c006-066f-48aa-eae1-0dd2e130609d"
      },
      "source": [
        "encoder_c.layers[1].get_weights()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[[[ 0.13476855, -0.10918425,  0.10076477,  0.12041579,\n",
              "             0.01533026, -0.00561188, -0.08473037,  0.05226232,\n",
              "             0.02974011,  0.11767384]],\n",
              " \n",
              "          [[-0.12731877,  0.07873096, -0.12301442,  0.08016694,\n",
              "            -0.05066879, -0.13553107, -0.1159028 , -0.02308157,\n",
              "            -0.09506493,  0.02595137]],\n",
              " \n",
              "          [[-0.1173927 ,  0.14667274, -0.10161826, -0.12996845,\n",
              "            -0.03060105,  0.00016269, -0.08850916,  0.12313148,\n",
              "             0.06616877,  0.07366093]]],\n",
              " \n",
              " \n",
              "         [[[-0.12960619, -0.13386141, -0.0583159 ,  0.0645499 ,\n",
              "             0.09340174,  0.08364811, -0.0086374 , -0.11358914,\n",
              "            -0.04338557, -0.08713959]],\n",
              " \n",
              "          [[ 0.07962169, -0.03543108,  0.00037313,  0.00409632,\n",
              "             0.04483921, -0.10158419,  0.07452077,  0.06298756,\n",
              "            -0.09712926,  0.05078771]],\n",
              " \n",
              "          [[-0.06808984,  0.06693837, -0.07972708,  0.08788405,\n",
              "            -0.06726237,  0.07127482,  0.13141814, -0.02879012,\n",
              "             0.03476627, -0.03839344]]],\n",
              " \n",
              " \n",
              "         [[[-0.04189777,  0.10933796, -0.13481785,  0.03056842,\n",
              "            -0.05658678, -0.00598799, -0.07993494,  0.05948699,\n",
              "            -0.0228445 , -0.08641467]],\n",
              " \n",
              "          [[ 0.02521915,  0.01152746,  0.01614904,  0.10150901,\n",
              "            -0.00163772,  0.13928142,  0.04748503, -0.0461502 ,\n",
              "             0.06761187,  0.11014916]],\n",
              " \n",
              "          [[-0.03949173,  0.02351392, -0.02452122, -0.12411293,\n",
              "             0.04194393, -0.05606974, -0.14662497, -0.08095483,\n",
              "             0.11852384,  0.08948237]]]],\n",
              " \n",
              " \n",
              " \n",
              "        [[[[-0.09314961, -0.10252655, -0.07769322, -0.07731341,\n",
              "            -0.03474696, -0.08526882, -0.08883149,  0.08706942,\n",
              "             0.01121875,  0.1467974 ]],\n",
              " \n",
              "          [[-0.01495673, -0.12537539,  0.05974966, -0.0579257 ,\n",
              "            -0.13188332, -0.07983047,  0.08560886,  0.0105164 ,\n",
              "            -0.11149064,  0.14761138]],\n",
              " \n",
              "          [[-0.0603066 ,  0.05853862, -0.0405514 ,  0.02055175,\n",
              "             0.12272435,  0.03528061, -0.09347399, -0.10451361,\n",
              "            -0.09745196, -0.03928007]]],\n",
              " \n",
              " \n",
              "         [[[-0.04022184,  0.02956292, -0.11795948, -0.08040476,\n",
              "             0.0784455 ,  0.04041145, -0.01488075,  0.05112085,\n",
              "            -0.13011914, -0.12819323]],\n",
              " \n",
              "          [[-0.07234559,  0.07174903, -0.13007914, -0.01429858,\n",
              "            -0.01445215, -0.09154583, -0.09565782, -0.1258028 ,\n",
              "             0.1111302 ,  0.10914236]],\n",
              " \n",
              "          [[ 0.05134225, -0.05206674, -0.11411835, -0.06075285,\n",
              "             0.11043306,  0.00131295,  0.05818219,  0.03812443,\n",
              "            -0.05388027,  0.11156385]]],\n",
              " \n",
              " \n",
              "         [[[-0.12102048, -0.02022728,  0.10162076, -0.0196378 ,\n",
              "             0.13596752, -0.08226174, -0.0092896 ,  0.14496797,\n",
              "             0.10145493, -0.03021469]],\n",
              " \n",
              "          [[ 0.12706406,  0.10622846, -0.08982042, -0.13024957,\n",
              "             0.03563828, -0.09040191,  0.0348828 , -0.04503588,\n",
              "             0.06602477,  0.12139595]],\n",
              " \n",
              "          [[ 0.02501659, -0.09421964,  0.07439672, -0.10652667,\n",
              "            -0.11567742,  0.03731121, -0.11061583, -0.04883598,\n",
              "            -0.04294037, -0.10890989]]]],\n",
              " \n",
              " \n",
              " \n",
              "        [[[[-0.06613225,  0.02223937, -0.05831759, -0.03429892,\n",
              "            -0.11489474, -0.09346715, -0.01060006,  0.08754241,\n",
              "             0.04858031,  0.12062671]],\n",
              " \n",
              "          [[-0.11292811,  0.06092703, -0.02743987,  0.07933045,\n",
              "            -0.09389845, -0.11273275, -0.08613764, -0.10217028,\n",
              "            -0.11630049,  0.08971702]],\n",
              " \n",
              "          [[-0.09457266,  0.10423707, -0.10110661, -0.14507367,\n",
              "             0.03379615, -0.05800878, -0.03380355, -0.09016485,\n",
              "            -0.03179331, -0.13196437]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1301181 , -0.10885695, -0.02295352,  0.0951497 ,\n",
              "             0.02202874,  0.09334581,  0.09813536,  0.07397972,\n",
              "             0.0886993 , -0.0340932 ]],\n",
              " \n",
              "          [[-0.03452827, -0.04319657, -0.08034277,  0.0144676 ,\n",
              "             0.0106739 , -0.06251799, -0.02955795,  0.06113063,\n",
              "            -0.02143315,  0.10525176]],\n",
              " \n",
              "          [[ 0.03623567,  0.01443754,  0.12156796,  0.04024913,\n",
              "            -0.14595424,  0.02339609,  0.01466014,  0.12886398,\n",
              "             0.12134705, -0.12826255]]],\n",
              " \n",
              " \n",
              "         [[[-0.03901536,  0.1064783 , -0.12199586,  0.12136558,\n",
              "            -0.12105924,  0.01922678,  0.0924786 ,  0.03072936,\n",
              "             0.14271049, -0.09106586]],\n",
              " \n",
              "          [[-0.02826085,  0.08156587,  0.1258655 , -0.0028484 ,\n",
              "             0.01818234,  0.10574172, -0.03436181, -0.02120042,\n",
              "             0.11452826,  0.03102513]],\n",
              " \n",
              "          [[-0.05989438,  0.07073489,  0.12800561, -0.0802242 ,\n",
              "            -0.02991011,  0.05410119, -0.02226578,  0.00428602,\n",
              "             0.06671868,  0.12493114]]]]], dtype=float32),\n",
              " array([-0.00555501,  0.00555885, -0.00555763, -0.00555879, -0.00555313,\n",
              "         0.00555793,  0.00554219,  0.00555883,  0.00555882,  0.0055588 ],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRfERhSxnt2v",
        "colab_type": "text"
      },
      "source": [
        "###New Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccbOxTeLiy25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "388a4b6c-6196-414d-cb10-8721eecb577e"
      },
      "source": [
        "input_img = Input(shape= (120, 160, 120 , 1))\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "x = Conv3D(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "x = MaxPool3D((2,2,2))(x)\n",
        "x= Dropout(0.8)(x)\n",
        "\n",
        "encoded_shape = K.int_shape(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(32, activation='selu')(x)\n",
        "x= Dense(16, activation='selu')(x)\n",
        "new_encoded = Dense(2, activation='softmax')(x)\n",
        "\n",
        "\n",
        "new_encoder=Model(input_img, new_encoded, name='new_encoder')\n",
        "new_encoder.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"new_encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 120, 160, 120, 10) 280       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_6 (MaxPooling3 (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 45000)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                1440032   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,446,294\n",
            "Trainable params: 1,446,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWEUWr9RdNNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "65eb96bb-9d61-4953-cbf7-f2c6105f97e9"
      },
      "source": [
        "encoded_input= Input(shape=(2,))\n",
        "x = Softmax(2)(encoded_input)\n",
        "#x = Dense(16, activation='selu')(encoded_input)\n",
        "#x= Dense(32, activation='selu')(x)\n",
        "#x= Dense(np.prod(encoded_shape[1:]))(x)\n",
        "#x= Reshape((encoded_shape[1], encoded_shape[2], encoded_shape[3], encoded_shape[4]))(x)\n",
        "\n",
        "#x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "#x = UpSampling3D((2,2,2))(x)\n",
        "#x= Dropout(0.8)(x)\n",
        "\n",
        "#x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "#x = UpSampling3D((2,2,2))(x)\n",
        "#x= Dropout(0.8)(x)\n",
        "\n",
        "#x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same')(x)\n",
        "#x = UpSampling3D((2,2,2))(x)\n",
        "#x= Dropout(0.8)(x)\n",
        "\n",
        "#x = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "smax = Model(encoded_input, x, name='smax')\n",
        "smax.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"smax\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "softmax_1 (Softmax)          (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClbpyiMckD2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "20785db4-af5a-4652-da9a-d4f7fb709eec"
      },
      "source": [
        "classifier= Model(input_img, smax(encoder_c(input_img)), name='classifier')\n",
        "classifier.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"classifier\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 2)                 1446294   \n",
            "_________________________________________________________________\n",
            "smax (Model)                 (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 1,446,294\n",
            "Trainable params: 1,446,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRuUnUgflAQy",
        "colab_type": "text"
      },
      "source": [
        "### Fitting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RbATVKlpqSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer_num in range(len(new_encoder.layers)-1):\n",
        "  new_encoder.layers[layer_num].set_weights(encoder_c.layers[layer_num].get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odY0e7oHrRY6",
        "colab_type": "text"
      },
      "source": [
        "Should we freeze them? Or just initial value?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNblAdMkrV5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#didn't freeze\n",
        "new_encoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YeHsGibrceu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "fb33f531-5cb6-47c7-9103-204c9f969faf"
      },
      "source": [
        "new_encoder.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"new_encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 120, 160, 120, 1)  0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 120, 160, 120, 10) 280       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 60, 80, 60, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 60, 80, 60, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 30, 40, 30, 10)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 30, 40, 30, 10)    2710      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_6 (MaxPooling3 (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 15, 20, 15, 10)    0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 45000)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                1440032   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,446,294\n",
            "Trainable params: 1,446,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJHBLhLRmmX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d66eff80-a8f4-4e2e-8196-23ca469ab7a9"
      },
      "source": [
        "new_encoder.predict(x_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.4474003e-09, 1.0000000e+00],\n",
              "       [8.7795353e-09, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH85ditynKbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "67530da9-c74b-4db7-9414-049ded4d96a3"
      },
      "source": [
        "new_encoder.predict(x_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.2797965e-09, 1.0000000e+00],\n",
              "       [7.3095707e-09, 1.0000000e+00],\n",
              "       [1.4675016e-09, 1.0000000e+00],\n",
              "       [2.6136755e-09, 1.0000000e+00],\n",
              "       [1.4367176e-09, 1.0000000e+00],\n",
              "       [3.2547344e-08, 1.0000000e+00],\n",
              "       [1.5889107e-08, 1.0000000e+00],\n",
              "       [4.2913171e-09, 1.0000000e+00],\n",
              "       [3.9997410e-09, 1.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXdKuu2xnHKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "753fb062-f448-4326-bbf1-9d3862817490"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvDRes0nVXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsUmH8dhmsKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVD4ub7re-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea6ae44b-5241-46e3-8628-bc8617633a0f"
      },
      "source": [
        "new_history= new_encoder.fit(x_train, y_train, batch_size=3, epochs=200, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9 samples, validate on 2 samples\n",
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 3.4176 - val_loss: 15.3371\n",
            "Epoch 73/200\n",
            "3/9 [=========>....................] - ETA: 0s - loss: 5.1264"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-a7b50878f880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_history\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnew_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSuL3svCsdxa",
        "colab_type": "text"
      },
      "source": [
        "###Freezed weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeAdfAoasgXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}