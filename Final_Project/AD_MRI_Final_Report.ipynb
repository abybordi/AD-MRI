{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AD-MRI_Final_Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsRDdEmuZW8a/h5cCS3P+W"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsJNvJxs2nmv",
        "colab_type": "text"
      },
      "source": [
        "# Classification and Visualization of Alzheimer’s Disease using Volumetric Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5TQr7rA2rZH",
        "colab_type": "text"
      },
      "source": [
        "Final Report, Spring 2020<br>\n",
        "CSc 84200 Deep Neural Networks and Applications with TensorFlow<br>\n",
        "CUNY Graduate Center<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVcAtyfLcxbW",
        "colab_type": "text"
      },
      "source": [
        "## Team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OISWeXwQcxml",
        "colab_type": "text"
      },
      "source": [
        "Daniel Brennan, Neuroscience PhD student<br>\n",
        "Arezoo Bybordi, Computer Science PhD student<br>\n",
        "Andrea Ceres, Data Science MS student<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dxxVx8O2rcr",
        "colab_type": "text"
      },
      "source": [
        "## Problem Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayBp1iABUCYJ",
        "colab_type": "text"
      },
      "source": [
        "Using a dataset of 980 labeled brain MRI images <sup>1</sup>, we model a deep neural network to classify brain scans as cognitively normal (CN) or indicative of Alzheimer's disease (AD). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xN_0tOh2riv",
        "colab_type": "text"
      },
      "source": [
        "## Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK-OOuqYYpnY",
        "colab_type": "text"
      },
      "source": [
        "The model presented incorporates a volumetric convolutional autoencoder to learn features that are useful in classifying images as either CN or AD. Furthermore, an alternative model is presented with similar 3D convolutional autoencoder design, whereby one convolutional layer is replaced by a custom inception block. The architectures for each autoencoder are loosely based on prior work done by Oh et. al. <sup>2</sup> As a point of comparison, two other models (with and without an inception block) are built without the autoencoder component. Tuning of hyperparameters primarily involved adjusting the rate of dropout to 0%, 20%, 50%, and 80%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOVogdxc2rmt",
        "colab_type": "text"
      },
      "source": [
        "### The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTUaEnzouFg2",
        "colab_type": "text"
      },
      "source": [
        "A dataset with 1098 brain images from OASIS was used in this project. A download script was provided and the data was stored in Google Drive. With Google Colab, all images were preprocessed, standardized, and normalized. Visual inspection was done to ensure success of the alignment procedure to standard T1 images. Of the original set, 980 brain images were split into train, validation, and test sets in the ratio 80:10:10. The combination of T1 and T2 contrasts<sup>3</sup> deemed more difficult than expected, and so it was decided that the project proceed with T1 standard MRI images only.<br>\n",
        "\n",
        "After initial experimentation with early parts of our code, it became clear that our limited computational power on Google Colab was illfit for the full volumetric data of dimension (120, 160, 120). Based on domain knowledge, the decision was made to use slices of the images that represent the area of the ventricles known to have an association with Alzheimer's disease. This resulted in a more manageable dimensionality of (120, 160, 16). In order to improve our model with the limited dataset we have, data augmentation was employed via image rotation in random directions. To address class imbalance, the rarer class was weighted more heavily as compensation. The calculation determined a ratio of 1.36 AD : 0.79 CN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-DHbXWB5QOv",
        "colab_type": "text"
      },
      "source": [
        "## Experimental Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ELiFflsqqWo",
        "colab_type": "text"
      },
      "source": [
        "The dataset was split into approximately 80% train, 10% validation, and 10% test. Experiments were run with a learning rate of 0.1 and a decay rate of 0.90. Patience was set to 10 epochs, which is reflected in the early stopping results below. Each model trained approximately 6.2 million parameters in the architecture. L1 and L2 regularization was set to 0 except during the inception block in the no dropout model. Stratification and data augmentation were employed unless specified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY3VmiMe-s31",
        "colab_type": "text"
      },
      "source": [
        "CAE: Classifier with Autoencoder<br>\n",
        "ICAE: Classifier with Inception Block and with Autoencoder<br>\n",
        "CnoAE: Classifier without Autoencoder<br>\n",
        "ICnoAE: Classifier with Inception Block and without Autoencoder<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlkkNa5JcQRm",
        "colab_type": "text"
      },
      "source": [
        "| Experiment name | Last two dense layers | Number of epochs | Inception block | Autoencoder | Dropout rate | Train Accuracy | Test Accuracy | Precision | Recall |\n",
        "|---|---|---|---|---|---|---|---|---|---|\n",
        "| CAE (no strat, no aug) | | 50 | no | yes | 80% | 0.63 | 0.37 | 0.60 | 0.60 |\n",
        "| CAE | | 100 | no | yes | 50% | 0.76 | 0.59 | 0.60 | 0.59 |\n",
        "| ICAE (no aug) | | 100 | yes | yes | 20% | 0.76 | 0.56 | 0.52 | 0.56 |\n",
        "| ICAE | | 25 | yes | yes | 80% | 0.64 | 0.63 | | |\n",
        "| ICAE_nodo_l1l2 | 256, 128 | 50 of 50 | yes | yes | 0% | 0.42 | 0.00 | 0.54 | 1.00 |\n",
        "| ICAE_50do | 256, 128 | 26 of 50 | yes | yes | 50% | 0.38 | 0.00 | 0.54 | 1.00 |\n",
        "| ICAE_80do | 256, 128 | 21 of 50 | yes | yes | 80% | 0.37 | 0.00 | 0.54 | 1.00 |\n",
        "| CAE_nodo | 1024, 64 | 34 of 50 | no | yes | 0% | 0.78 | 0.49 | 0.49 | 0.49 |\n",
        "| CAE_50do | 1024, 64 | 21 of 50 | no | yes | 50% | 0.53 | 0.37 | 0.13 | 0.37 |\n",
        "| CAE_80do | 1024, 64 | 22 of 50 | no | yes | 80% | 0.58 | 0.63 | 0.40 | 0.63 |\n",
        "| ICnoAE_nodo_l1l2 | 256, 128 | 50 of 50| yes | no | 0% | 0.38 | 0.00 | 0.54 | 1.00 |\n",
        "| ICnoAE_50do | 256, 128 | 11 of 50 | yes | no | 50% | 0.61 | 0.63 | 0.40 | 0.63 |\n",
        "| ICnoAE_80do | 256, 128 | 38 of 50 | yes | no | 80% | 0.36 | 0.00 |  0.54 | 1.00 |\n",
        "| CnoAE_nodo | 1024, 64 | 22 of 50 | no | no | 0% | 0.59 | 0.56 | 0.57 | 0.56 |\n",
        "| CnoAE_50do | 1024, 64 | 20 of 50 | no | no | 50% | 0.64 | 0.63 | 0.40 | 0.63 |\n",
        "| CnoAE_80do | 1024, 64 | 18 of 50 | no | no | 80% | 0.36 | 0.37 | 0.13 | 0.37 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZVkqkp6ylA8",
        "colab_type": "text"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYL1GJaEyqj7",
        "colab_type": "text"
      },
      "source": [
        "In the timeframe of this project, we sought to  recreate the neural network architecture based on an academic paper. Our initial model required adjustments to fit the limitations of our time and computing capacities. Whether due to the small dataset, or to errors in the architecture or experimental setup, or to failure in finetuning experimental hyperparameters and other factors optimally, our results did not yield significant gains for the task of classifying volumetric MRI images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTnanLrW5rs4",
        "colab_type": "text"
      },
      "source": [
        "## Contributions\n",
        "\n",
        "Below is a list of contributions by team members:\n",
        "\n",
        "* Data preprocessing (Daniel)\n",
        "* Creating Convolutional Autoencoder (Arezoo)\n",
        "* Creating Convolutional Autoencoder with Inception module (Andrea)\n",
        "* Creating a classifier using CAE (Arezoo)\n",
        "* Creating a generator to solve the big data issues (Batch size 2, non stratified train and test data, non-augmented data) (Arezoo)\n",
        "* New generator with increase in batch size, stratified train and test data and augmented training data by rotation (Daniel)\n",
        "* Creating end-to-end architecture (having the autoencoder and  classifier in one architecture) (Daniel)\n",
        "* Dealing with class imbalance with further assigning weights to different classes (Andrea)\n",
        "* Experiments done by changing the input size (16 slices), increasing batch size (Daniel)\n",
        "* Experiments done by changing the architecture (increasing number of neurons in the dense layer), etc. (Daniel)\n",
        "* Experiments done on training model (Andrea)\n",
        "* Making architecture plots (Andrea)\n",
        "* Visualization of the convolutional layers (Arezoo)\n",
        "* GitHub wiki initialization (Andrea)\n",
        "* Presentation initialization (Arezoo)\n",
        "* Add model functionality without autoencoder for comparison (Andrea)\n",
        "* Experiments done with and without autoencoder (Andrea)\n",
        "* Clean up and functionalize final code and create pipeline (Andrea)\n",
        "* Add preprocessing to final code (Daniel)\n",
        "* Final report (Andrea)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzJXW12W54f9",
        "colab_type": "text"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4njD6rny5r0e",
        "colab_type": "text"
      },
      "source": [
        "<sup>1</sup>OASIS-3: Longitudinal Neuroimaging, Clinical, and Cognitive Dataset for Normal Aging and Alzheimer’s Disease. OASIS: Open Access Series of Imaging Studies. https://www.oasis-brains.org<br>\n",
        "<sup>2</sup>Oh, K., Chung, Y., Kim, K.W. et al. Classification and Visualization of Alzheimer’s Disease using Volumetric Convolutional Neural Network and Transfer Learning. Sci Rep 9, 18150 (2019). https://doi.org/10.1038/s41598-019-54548-6<br>\n",
        "<sup>3</sup>Misaki, M., Savitz, J., Zotev, V., Phillips, R., Yuan, H., Young, K.D., Drevets, W.C. and Bodurka, J. (2015), Contrast enhancement by combining T 1‐ and T 2‐weighted structural brain MR Images. Magn. Reson. Med., 74: 1609-1620. https://doi:10.1002/mrm.25560<br>"
      ]
    }
  ]
}