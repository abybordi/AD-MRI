{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":" ICAE_Classifier_Generator_VentriclesOnly_DB.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Xt2onyB1zQ9Z","colab_type":"code","colab":{}},"source":["%matplotlib inline \n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from sklearn.utils import class_weight"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8ug2tfPzWqa","colab_type":"code","outputId":"d81c8d9d-0186-4358-c96e-240fc93e92ab","executionInfo":{"status":"ok","timestamp":1589312008132,"user_tz":240,"elapsed":1542,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vXKe3JlXzQ9d","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IT-I0pU4zQ9g","colab_type":"code","outputId":"de42bcbe-9713-4bfa-e3f3-8bcc9e36b5a9","executionInfo":{"status":"ok","timestamp":1589312008133,"user_tz":240,"elapsed":1513,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","print('Tensorflow version:', tf.__version__)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Tensorflow version: 2.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nPFgeYTuzQ9k","colab_type":"text"},"source":["#### Create Train/Test Subset"]},{"cell_type":"code","metadata":{"id":"qYrPlrRqzQ9k","colab_type":"code","outputId":"a79bcd1a-df73-4023-e829-0efb1710662c","executionInfo":{"status":"ok","timestamp":1589312008853,"user_tz":240,"elapsed":2216,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["%cd /content/drive/My Drive/AD_MRI\n","import pickle\n","import pandas as pd\n","with open('AD_MRI_Master','rb') as f:\n","    master_list = pickle.load(f)\n","    \n","master_sheet = pd.DataFrame.from_dict(master_list, orient='index')\n","display(master_sheet.head())\n","\n","from sklearn.model_selection import train_test_split\n","\n","train_list,test_list,train_label,test_label = train_test_split(master_sheet.subject.values,\n","                                                               master_sheet.diagnosis.values\n","                                                               ,random_state = 1337,test_size=0.2)\n","\n","\n","AD_count = 0\n","for lab in train_label:\n","    if lab == 'AD':\n","        AD_count +=1\n","\n","print('train_ratio AD: ',AD_count/len(train_label))\n","\n","AD_count = 0\n","for lab in test_label:\n","    if lab == 'AD':\n","        AD_count +=1\n","print('test_ratio AD: ',AD_count/len(test_label))\n","#ratios are the same, we're good to go. \n","\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/AD_MRI\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>subject</th>\n","      <th>age</th>\n","      <th>diagnosis</th>\n","      <th>scan_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>OAS30001</th>\n","      <td>OAS30001</td>\n","      <td>65.0</td>\n","      <td>CN</td>\n","      <td>OAS30001_MR_d0129</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30002</th>\n","      <td>OAS30002</td>\n","      <td>68.0</td>\n","      <td>CN</td>\n","      <td>OAS30002_MR_d0371</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30003</th>\n","      <td>OAS30003</td>\n","      <td>60.0</td>\n","      <td>CN</td>\n","      <td>OAS30003_MR_d0558</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30004</th>\n","      <td>OAS30004</td>\n","      <td>58.0</td>\n","      <td>CN</td>\n","      <td>OAS30004_MR_d1101</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30005</th>\n","      <td>OAS30005</td>\n","      <td>48.0</td>\n","      <td>CN</td>\n","      <td>OAS30005_MR_d0143</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           subject   age diagnosis            scan_ID\n","OAS30001  OAS30001  65.0        CN  OAS30001_MR_d0129\n","OAS30002  OAS30002  68.0        CN  OAS30002_MR_d0371\n","OAS30003  OAS30003  60.0        CN  OAS30003_MR_d0558\n","OAS30004  OAS30004  58.0        CN  OAS30004_MR_d1101\n","OAS30005  OAS30005  48.0        CN  OAS30005_MR_d0143"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["train_ratio AD:  0.36862244897959184\n","test_ratio AD:  0.3622448979591837\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWz1F457zQ9r","colab_type":"text"},"source":["### Create Generator"]},{"cell_type":"code","metadata":{"id":"Q3IK5qfYzQ9r","colab_type":"code","colab":{}},"source":["processed_dir = '/content/drive/My Drive/AD_MRI/PROCESSED/'\n","\n","# custom data generator.\n","import random\n","import scipy\n","import numpy as np\n","import cv2\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","import random\n","\n","import scipy\n","\n","def labels_to_categorical(labels):\n","    le = LabelEncoder()\n","    le.fit([\"CN\", \"AD\"])\n","    num_lab=to_categorical(le.transform(labels),num_classes=2)\n","    return num_lab\n","\n","\n","\n","class MyDataGenerator(Sequence):\n","    \"\"\"Generates data for Keras\n","    Sequence based data generator. Suitable for building data generator for training and prediction.\n","    \"\"\"\n","    def __init__(self, list_IDs, processed_dir,augment=False, \n","                 to_fit=True, batch_size=32, dim=(120, 160, 120, 1),\n","                 n_classes=2, shuffle=True, ventricals_only = True):\n","        \"\"\"Initialization\n","        :param list_IDs: list of all 'label' PATHS\n","        :param labels: list of image labels ***MUST ALREADY BE (N X 2) ARRAY***\n","        :param image_path: path to images location\n","        # \n","        :param to_fit: True to return X and y, False to return X only\n","        :param batch_size: batch size at each iteration\n","        :param dim: tuple indicating image dimension\n","        :param n_channels: number of image channels\n","        :param n_classes: number of output masks\n","        :param shuffle: True to shuffle label indexes after every epoch\n","        \"\"\"\n","        self.list_IDs = list_IDs\n","        self.processed_dir = processed_dir\n","        #self.labels = labels\n","        self.augment = augment\n","        self.ventricals_only = ventricals_only\n","        #self.image_path = image_path not needed\n","        #self.mask_path = mask_path   not needed\n","        self.to_fit = to_fit\n","        self.batch_size = batch_size\n","        self.dim = dim\n","        #self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\n","        :return: number of batches per epoch\n","        \"\"\"\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        \"\"\"Generate one batch of data\n","        :param index: index of the batch\n","        :return: X and y when fitting. X only when predicting\n","        \"\"\"\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # Generate data\n","        X,y = self._load_data(list_IDs_temp)\n","        X=np.float32(X)\n","        if self.ventricals_only:\n","          X = X[:,:,:,50:66,:]\n","        if self.to_fit:\n","            y= {'classifier':y,'ICAE_decoder':X}\n","            return X,y\n","        else:\n","            return X\n","\n","    def on_epoch_end(self):\n","        \"\"\"Updates indexes after each epoch\n","        \"\"\"\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def _load_data(self, list_IDs_temp):\n","        \"\"\"Generates data containing batch_size images\n","        :param list_IDs_temp: list of label ids to load\n","        :return: batch of images\n","        \"\"\"\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim))\n","        y = np.empty((self.batch_size,self.n_classes), dtype=int)\n","        \n","        \n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            #start X\n","            with open(self.processed_dir+ID+'_data','rb') as f:\n","                data = pickle.load(f)\n","                \n","            \n","            x_reshape= np.reshape(data['image'], (120, 160, 120, 1) )\n","            if self.augment == True:\n","                x_reshape = scipy.ndimage.rotate(x_reshape, \n","                                           axes=random.choice([(0,1),(0,2),(1,2)]),\n","                                           angle=random.choice([360-15,15]),\n","                                           reshape=False)\n","            X[i,] = x_reshape\n","            \n","            #start y\n","            y[i,] = labels_to_categorical([data['diagnosis']])\n","            \n","            \n","\n","        return X,y\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpzZF63uzQ9w","colab_type":"code","colab":{}},"source":["processed_dir = '/content/drive/My Drive/AD_MRI/PROCESSED/'\n","mdg= MyDataGenerator(test_list,processed_dir,to_fit=True,augment=True,batch_size=2)\n","\n","X,pred=mdg.__getitem__(0)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUEOTwa87Kwl","colab_type":"code","outputId":"448f240e-78b3-42d3-afb9-42ba0dcb0a6c","executionInfo":{"status":"ok","timestamp":1589312010030,"user_tz":240,"elapsed":3379,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X.shape"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 120, 160, 16, 1)"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"RHJs-MSozQ92","colab_type":"text"},"source":["##### --- Start adaptation from Arezoo's notebook ---"]},{"cell_type":"markdown","metadata":{"id":"pf0QJqFOzQ-a","colab_type":"text"},"source":["#### Building Encoder"]},{"cell_type":"code","metadata":{"id":"NQHRA3MVzQ-b","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv3D, MaxPool3D, Dropout, \\\n","    Flatten, Conv3DTranspose, UpSampling3D, Reshape\n","from tensorflow.keras.layers import Input\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ayyv4uXRzQ-d","colab_type":"code","outputId":"f1906029-121a-4a25-fcaf-e25559c95b6f","executionInfo":{"status":"ok","timestamp":1589312010032,"user_tz":240,"elapsed":3332,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"source":["input_img = Input(shape=(120, 160, 120 , 1), name='Input')\n","\n","print('\\ninput shape:', input_img.shape)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(input_img)\n","x = MaxPool3D((2,2,2), name='MaxPooling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = MaxPool3D((2,2,2), name='MaxPooling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_3')(x)\n","x = MaxPool3D((2,2,2), name='MaxPooling_3')(x)\n","x = Dropout(0.8, name='DropOut_3')(x)\n","\n","conv_shape = K.int_shape(x)\n","\n","print('shape after convolutions:', conv_shape)\n","\n","# x = Flatten(name='Flatten')(x)\n","\n","# x = Dense(32, activation='selu', name='SELU_1')(x)\n","# x = Dense(16, activation='selu', name='SELU_2')(x)\n","\n","# encoded = Dense(2, name='Encoded')(x)\n","\n","# encoded_shape = K.int_shape(encoded)\n","\n","# print('final encoded shape:', encoded_shape, '\\n')\n","\n","encoded = x\n","encoded_shape = K.int_shape(encoded)\n","\n","\n","encoder = Model(input_img, encoded, name='CAE_encoder')\n","encoder.summary()\n"],"execution_count":49,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 120, 160, 120, 1)\n","shape after convolutions: (None, 15, 20, 15, 10)\n","Model: \"CAE_encoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input (InputLayer)           [(None, 120, 160, 120, 1) 0         \n","_________________________________________________________________\n","Convolution_1 (Conv3D)       (None, 120, 160, 120, 10) 280       \n","_________________________________________________________________\n","MaxPooling_1 (MaxPooling3D)  (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","DropOut_1 (Dropout)          (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","Convolution_2 (Conv3D)       (None, 60, 80, 60, 10)    2710      \n","_________________________________________________________________\n","MaxPooling_2 (MaxPooling3D)  (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","DropOut_2 (Dropout)          (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","Convolution_3 (Conv3D)       (None, 30, 40, 30, 10)    2710      \n","_________________________________________________________________\n","MaxPooling_3 (MaxPooling3D)  (None, 15, 20, 15, 10)    0         \n","_________________________________________________________________\n","DropOut_3 (Dropout)          (None, 15, 20, 15, 10)    0         \n","=================================================================\n","Total params: 5,700\n","Trainable params: 5,700\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxKAey2vzQ-f","colab_type":"code","colab":{}},"source":["# model only: post-encoder\n","\n","# x = Flatten(name='Flatten')(x)\n","\n","# x = Dense(32, activation='selu', name='SELU_1')(x)\n","# x = Dense(16, activation='selu', name='SELU_2')(x)\n","\n","# encoded = Dense(2, name='Encoded')(x)\n","\n","# encoded_shape = K.int_shape(encoded)\n","\n","# print('final encoded shape:', encoded_shape, '\\n')\n","\n","# encoder = Model(input_img, encoded, name='CAE_encoder')\n","# encoder.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XoHcBk7SzQ-h","colab_type":"text"},"source":["##### CAE Encoder layers\n","\n","Input\n","\n","    120 x 160 x 120 x 1\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    120 x 160 x 120 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30 x 40 x 30 x 10\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    30 x 40 x 30 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    15 x 20 x 15 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    15 x 20 x 15 x 10\n","    \n","\n","<!-- ###### In the Classifier only:\n","\n","Flatten\n","\n","    45000\n","\n","Dense layer (32 channels, SELU activation)\n","\n","    32\n","\n","Dense layer (16 channels, SELU activation)\n","\n","    16\n","\n","Dense layer (2 possible outputs)\n","\n","    2\n"," -->"]},{"cell_type":"markdown","metadata":{"id":"b1o-Xo2SzQ-h","colab_type":"text"},"source":["#### Building Decoder"]},{"cell_type":"code","metadata":{"id":"KiVNE5H4yPaU","colab_type":"code","outputId":"d5884750-4779-45c6-919f-4f45ec2a1a2b","executionInfo":{"status":"ok","timestamp":1589312010034,"user_tz":240,"elapsed":3320,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoded_shape"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 15, 20, 15, 10)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"NnPBrgD6zQ-i","colab_type":"code","outputId":"012503f0-8ce3-4273-ea06-33f8c7697868","executionInfo":{"status":"ok","timestamp":1589312010289,"user_tz":240,"elapsed":3566,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["encoded_input = Input(shape=(encoded_shape[1],encoded_shape[2], encoded_shape[3], encoded_shape[4],), name='Encoded')\n","\n","x = encoded_input\n","\n","print('\\ninput shape:', encoded_input.shape)\n","\n","# x = Dense(16, activation='selu', name='SELU_2')(encoded_input)\n","# x = Dense(32, activation='selu', name='SELU_1')(x)\n","# x = Dense(np.prod(conv_shape[1:]), name='Product')(x)\n","# x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3], conv_shape[4]), name='Reshape')(x)\n","\n","# print('shape after reshape:', K.int_shape(x))\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_3')(x)\n","x = UpSampling3D((2,2,2), name='UpSampling_3')(x)\n","x = Dropout(0.8, name='DropOut_3')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = UpSampling3D((2,2,2), name='UpSampling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(x)\n","x = UpSampling3D((2,2,2), name='UpSampling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","# decoded = Dense(1, activation='sigmoid', name='Output')(x)\n","decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same', name='Output')(x)\n","\n","print('final decoded shape:', K.int_shape(decoded), '\\n')\n","\n","decoder = Model(encoded_input, decoded, name='CAE_decoder')\n","decoder.summary()\n"],"execution_count":52,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 15, 20, 15, 10)\n","final decoded shape: (None, 120, 160, 120, 1) \n","\n","Model: \"CAE_decoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoded (InputLayer)         [(None, 15, 20, 15, 10)]  0         \n","_________________________________________________________________\n","Convolution_3 (Conv3DTranspo (None, 15, 20, 15, 10)    2710      \n","_________________________________________________________________\n","UpSampling_3 (UpSampling3D)  (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","DropOut_3 (Dropout)          (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","Convolution_2 (Conv3DTranspo (None, 30, 40, 30, 10)    2710      \n","_________________________________________________________________\n","UpSampling_2 (UpSampling3D)  (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","DropOut_2 (Dropout)          (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","Convolution_1 (Conv3DTranspo (None, 60, 80, 60, 10)    2710      \n","_________________________________________________________________\n","UpSampling_1 (UpSampling3D)  (None, 120, 160, 120, 10) 0         \n","_________________________________________________________________\n","DropOut_1 (Dropout)          (None, 120, 160, 120, 10) 0         \n","_________________________________________________________________\n","Output (Conv3DTranspose)     (None, 120, 160, 120, 1)  271       \n","=================================================================\n","Total params: 8,401\n","Trainable params: 8,401\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZAaPqPwezQ-k","colab_type":"text"},"source":["<!-- \n"," ###### In the Classifier only:\n","\n","\n","Input\n","\n","    2\n","\n","Dense layer (16 channels, SELU activation)\n","\n","    16\n","\n","Dense layer (32 channels, SELU activation)\n","\n","    32\n","\n","Dense layer (product of encoded_shape dimensions 15x20x15x10)\n","\n","    45000\n","\n","Reshape to encoded_shape dimensions\n","\n","    15 x 20 x 15 x 10 \n","    \n","     -->\n","##### CAE Decoder layers\n","\n","Input\n","\n","    15 x 20 x 15 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    15 x 20 x 15 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30x 40 x 30 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    30 x 40 x 30 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    120 x 160 x 120 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    120 x 160 x 120 x 10\n","\n","Convolutional transpose layer (1 channel, 3x3x3 kernel, sigmoid activation, padding)\n","\n","    120 x 160 x 120 x 1\n"]},{"cell_type":"markdown","metadata":{"id":"V3szdqC1zQ-k","colab_type":"text"},"source":["#### Building Autoencoder"]},{"cell_type":"code","metadata":{"id":"QKb0jdkXzQ-m","colab_type":"code","outputId":"086e8768-bc21-43f0-f2c5-8a24d1866566","executionInfo":{"status":"ok","timestamp":1589312010290,"user_tz":240,"elapsed":3559,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["autoencoder = Model(input_img, decoder(encoder(input_img)), name='CAE_autoencoder')\n","autoencoder.summary()"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Model: \"CAE_autoencoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input (InputLayer)           [(None, 120, 160, 120, 1) 0         \n","_________________________________________________________________\n","CAE_encoder (Model)          (None, 15, 20, 15, 10)    5700      \n","_________________________________________________________________\n","CAE_decoder (Model)          (None, 120, 160, 120, 1)  8401      \n","=================================================================\n","Total params: 14,101\n","Trainable params: 14,101\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wKlx4vFKzQ-o","colab_type":"code","colab":{}},"source":["autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","#hist = autoencoder.fit(x_train, x_train, epochs=1, verbose=1, validation_data=(x_test, x_test)) # epochs=200"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NdI_IT8bzQ-r","colab_type":"text"},"source":["##### --- End adaption from Arezoo's notebook ---"]},{"cell_type":"markdown","metadata":{"id":"ZpFLNADNzQ-r","colab_type":"text"},"source":["### ICAE Inception Model"]},{"cell_type":"markdown","metadata":{"id":"I9if6blZzQ-s","colab_type":"text"},"source":["#### Building Encoder"]},{"cell_type":"code","metadata":{"id":"1_5StYluzQ-s","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import TensorBoard\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv3D, MaxPool3D, Dropout, Flatten, \\\n","    Conv3DTranspose, UpSampling3D, Reshape\n","from tensorflow.keras.layers import Input\n","\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.regularizers import l1_l2\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGFALorfzQ-v","colab_type":"code","colab":{}},"source":["def inception_module(input, filter_operation):\n","    \"\"\"\n","    filter_operation is a list of inception operations for:\n","        1x1x1 kernel, \n","        1x1x1 then 3x3x3 kernels, \n","        1x1x1 then 3x3x3 then 3x3x3 kernels, \n","        and 3x3x3 maxpooling then 1x1x1 kernels, \n","            respectively.\n","    \"\"\"\n","    \n","    # According to Nature paper (Oh et. al.), l1 and l2 values of 10e-4 performed the best \n","    #   from experimentation with 0.01, 0.001, 0.0001, 0.00001 values.\n","    l1_value = 10e-4\n","    l2_value = 10e-4\n","\n","    # Branch A\n","    branch_1x1x1 = Conv3D(filter_operation[0], kernel_size=(1, 1, 1), activation='relu', \\\n","                          padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                          name='Branch_A_1x1x1')(input)\n","\n","    # Branch B\n","    branch_3x3x3_initial = Conv3D(filter_operation[1], kernel_size=(1, 1, 1), activation='relu', \\\n","                                  padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                  name='Branch_B_1x1x1')(input)\n","    branch_3x3x3 = Conv3D(filter_operation[1], kernel_size=(3, 3, 3), activation='relu', \\\n","                          padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                          name='Branch_B_3x3x3')(branch_3x3x3_initial)\n","\n","    # Branch C\n","    branch_double_3x3x3_initial = Conv3D(filter_operation[2], kernel_size=(1, 1, 1), \\\n","                                         activation='relu', padding='same', \\\n","                                         kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                         name='Branch_C_1x1x1')(input)\n","    branch_double_3x3x3_middle = Conv3D(filter_operation[2], kernel_size=(3, 3, 3), \\\n","                                        activation='relu', padding='same', \\\n","                                        kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                        name='Branch_C_1st_3x3x3')(branch_double_3x3x3_initial)\n","    branch_double_3x3x3 = Conv3D(filter_operation[2], kernel_size=(3, 3, 3), activation='relu', \\\n","                                 padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                 name='Branch_C_2nd_3x3x3')(branch_double_3x3x3_middle)\n","\n","    # Branch D\n","    branch_maxpool_3x3x3_initial = MaxPool3D(pool_size=(3, 3, 3), strides=(1, 1, 1), \\\n","                                             padding='same', name='Branch_D_3x3x3_maxpool')(input)\n","    branch_maxpool_3x3x3 = Conv3D(filter_operation[3], kernel_size=(1, 1, 1), activation='relu', \\\n","                                  padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                  name='Branch_D_1x1x1')(branch_maxpool_3x3x3_initial)\n","    \n","    # Merge branches\n","    modules = [branch_1x1x1, branch_3x3x3, branch_double_3x3x3, branch_maxpool_3x3x3]\n","    merged_module = concatenate(modules, name='Inception_Merged') # axis=-1\n","    \n","    return merged_module\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HX5sfPuTzQ-x","colab_type":"code","outputId":"883e5bf5-1178-4f3e-ed63-6026c44a15a0","executionInfo":{"status":"ok","timestamp":1589312010898,"user_tz":240,"elapsed":4152,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["input_img = Input(shape= (120, 160, 16 , 1), name='Input')\n","\n","print('\\ninput shape:', input_img.shape)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(input_img)\n","x = MaxPool3D((2,2,2), name='MaxPooling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = MaxPool3D((2,2,2), name='MaxPooling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","# filter_operations = [40, 40, 40, 40]\n","filter_operations = [10, 10, 10, 10]\n","\n","x = inception_module(x, filter_operations)\n","x = MaxPool3D((2,2,2), name='Inception_MaxPooling')(x)\n","encoded = Dropout(0.8, name='DropOut_3')(x)\n","\n","# print('shape after inception:', K.int_shape(x))\n","\n","# ## for model only\n","# encoded = Flatten(name='Flatten')(encoded)\n","# encoded = Dense(1, activation='sigmoid', name='Prediction')(encoded)\n","# ##\n","\n","encoder = Model(input_img, encoded, name='ICAE_encoder')\n","\n","encoded_shape = K.int_shape(encoded)\n","print('final encoded shape:', encoded_shape, '\\n')\n","\n","encoder.summary(positions=[.35, .64, .71, 1.]) # adjusts print settings to minimize truncation\n"],"execution_count":57,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 120, 160, 16, 1)\n","final encoded shape: (None, 15, 20, 2, 40) \n","\n","Model: \"ICAE_encoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                      Output Shape                Param  Connected to                 \n","==================================================================================================\n","Input (InputLayer)                [(None, 120, 160, 16, 1)]   0                                   \n","__________________________________________________________________________________________________\n","Convolution_1 (Conv3D)            (None, 120, 160, 16, 10)    280    Input[0][0]                  \n","__________________________________________________________________________________________________\n","MaxPooling_1 (MaxPooling3D)       (None, 60, 80, 8, 10)       0      Convolution_1[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_1 (Dropout)               (None, 60, 80, 8, 10)       0      MaxPooling_1[0][0]           \n","__________________________________________________________________________________________________\n","Convolution_2 (Conv3D)            (None, 60, 80, 8, 10)       2710   DropOut_1[0][0]              \n","__________________________________________________________________________________________________\n","MaxPooling_2 (MaxPooling3D)       (None, 30, 40, 4, 10)       0      Convolution_2[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_2 (Dropout)               (None, 30, 40, 4, 10)       0      MaxPooling_2[0][0]           \n","__________________________________________________________________________________________________\n","Branch_C_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_B_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_C_1st_3x3x3 (Conv3D)       (None, 30, 40, 4, 10)       2710   Branch_C_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_D_3x3x3_maxpool (MaxPoolin (None, 30, 40, 4, 10)       0      DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_A_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_B_3x3x3 (Conv3D)           (None, 30, 40, 4, 10)       2710   Branch_B_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_C_2nd_3x3x3 (Conv3D)       (None, 30, 40, 4, 10)       2710   Branch_C_1st_3x3x3[0][0]     \n","__________________________________________________________________________________________________\n","Branch_D_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    Branch_D_3x3x3_maxpool[0][0] \n","__________________________________________________________________________________________________\n","Inception_Merged (Concatenate)    (None, 30, 40, 4, 40)       0      Branch_A_1x1x1[0][0]         \n","                                                                     Branch_B_3x3x3[0][0]         \n","                                                                     Branch_C_2nd_3x3x3[0][0]     \n","                                                                     Branch_D_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Inception_MaxPooling (MaxPooling3 (None, 15, 20, 2, 40)       0      Inception_Merged[0][0]       \n","__________________________________________________________________________________________________\n","DropOut_3 (Dropout)               (None, 15, 20, 2, 40)       0      Inception_MaxPooling[0][0]   \n","==================================================================================================\n","Total params: 11,560\n","Trainable params: 11,560\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xXTWo7y5zQ-z","colab_type":"text"},"source":["##### ICAE Encoder layers\n","\n","Input\n","\n","    120 x 160 x 120 x 1\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    120 x 160 x 120 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30 x 40 x 30 x 10\n","\n","Inception branched layers\n","\n","    A: 30 x 40 x 30 x 10\n","\n","    B: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n","\n","    C: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n","\n","    D: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n","\n","Inception merged layer\n","\n","    30 x 40 x 30 x 40\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    15 x 20 x 15 x 40\n","\n","Dense layer (2 possible outputs, SoftMax activation)\n","\n","    15 x 20 x 15 x 2\n"]},{"cell_type":"markdown","metadata":{"id":"KsOlxg4vzQ-z","colab_type":"text"},"source":["#### Building Decoder"]},{"cell_type":"code","metadata":{"id":"AyLnMo4szQ-0","colab_type":"code","outputId":"5aa0fe71-1ff9-46c1-a5ed-9a307e487d5e","executionInfo":{"status":"ok","timestamp":1589312011249,"user_tz":240,"elapsed":4494,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["encoded_input= Input(shape=(encoded_shape[1],encoded_shape[2], \\\n","                            encoded_shape[3], encoded_shape[4],), name='Input')\n","\n","print('\\ninput shape:', encoded_input.shape)\n","\n","filter_operations = [40, 40, 40, 40]\n","filter_operations = [10, 10, 10, 10]\n","combined_dim = sum(filter_operations) # taken from encoder\n","\n","x = Dense(combined_dim, activation='selu', name='SELU')(encoded_input)\n","\n","### ************\n","x = encoded_input\n","x = inception_module(x, filter_operations)\n","### ************\n","# print('shape after inception:', K.int_shape(x))\n","\n","x = UpSampling3D((2,2,2), name='Inception_Upsampling')(x)\n","x = Dropout(0.8, name='DropOut_3')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = UpSampling3D((2,2,2), name='Upsampling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(x)\n","x = UpSampling3D((2,2,2), name='Upsampling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","# decoded = Dense(1, activation='sigmoid', name='Output')(x)\n","decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same', name='Output')(x)\n","\n","print('final decoded shape:', K.int_shape(decoded), '\\n')\n","\n","decoder = Model(encoded_input, decoded, name='ICAE_decoder')\n","decoder.summary(positions=[.35, .64, .71, 1.])\n"],"execution_count":58,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 15, 20, 2, 40)\n","final decoded shape: (None, 120, 160, 16, 1) \n","\n","Model: \"ICAE_decoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                      Output Shape                Param  Connected to                 \n","==================================================================================================\n","Input (InputLayer)                [(None, 15, 20, 2, 40)]     0                                   \n","__________________________________________________________________________________________________\n","Branch_C_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_B_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_C_1st_3x3x3 (Conv3D)       (None, 15, 20, 2, 10)       2710   Branch_C_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_D_3x3x3_maxpool (MaxPoolin (None, 15, 20, 2, 40)       0      Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_A_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_B_3x3x3 (Conv3D)           (None, 15, 20, 2, 10)       2710   Branch_B_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_C_2nd_3x3x3 (Conv3D)       (None, 15, 20, 2, 10)       2710   Branch_C_1st_3x3x3[0][0]     \n","__________________________________________________________________________________________________\n","Branch_D_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Branch_D_3x3x3_maxpool[0][0] \n","__________________________________________________________________________________________________\n","Inception_Merged (Concatenate)    (None, 15, 20, 2, 40)       0      Branch_A_1x1x1[0][0]         \n","                                                                     Branch_B_3x3x3[0][0]         \n","                                                                     Branch_C_2nd_3x3x3[0][0]     \n","                                                                     Branch_D_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Inception_Upsampling (UpSampling3 (None, 30, 40, 4, 40)       0      Inception_Merged[0][0]       \n","__________________________________________________________________________________________________\n","DropOut_3 (Dropout)               (None, 30, 40, 4, 40)       0      Inception_Upsampling[0][0]   \n","__________________________________________________________________________________________________\n","Convolution_2 (Conv3DTranspose)   (None, 30, 40, 4, 10)       10810  DropOut_3[0][0]              \n","__________________________________________________________________________________________________\n","Upsampling_2 (UpSampling3D)       (None, 60, 80, 8, 10)       0      Convolution_2[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_2 (Dropout)               (None, 60, 80, 8, 10)       0      Upsampling_2[0][0]           \n","__________________________________________________________________________________________________\n","Convolution_1 (Conv3DTranspose)   (None, 60, 80, 8, 10)       2710   DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Upsampling_1 (UpSampling3D)       (None, 120, 160, 16, 10)    0      Convolution_1[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_1 (Dropout)               (None, 120, 160, 16, 10)    0      Upsampling_1[0][0]           \n","__________________________________________________________________________________________________\n","Output (Conv3DTranspose)          (None, 120, 160, 16, 1)     271    DropOut_1[0][0]              \n","==================================================================================================\n","Total params: 23,561\n","Trainable params: 23,561\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"opGBnug7zQ-3","colab_type":"text"},"source":["##### ICAE Decoder layers\n","\n","Input\n","\n","    15 x 20 x 15 x 10\n","\n","Inception branched layers\n","\n","    A: 15 x 20 x 15 x 10\n","\n","    B: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n","\n","    C: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n","\n","    D: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30x 40 x 30 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    30 x 40 x 30 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    120 x 160 x 120 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    120 x 160 x 120 x 10\n","\n","Convolutional transpose layer (1 channel, 3x3x3 kernel, sigmoid activation, padding)\n","\n","    120 x 160 x 120 x 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ol-4Dt7WzQ-4","colab_type":"text"},"source":["#### Building Autoencoder"]},{"cell_type":"code","metadata":{"id":"5xQYaVA2ssdV","colab_type":"code","outputId":"0630af30-bb61-4363-c0bb-607c4ea8bdcf","executionInfo":{"status":"ok","timestamp":1589312011250,"user_tz":240,"elapsed":4487,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["#classifier\n","\n","encoded_input = Input(shape=(encoded_shape[1],encoded_shape[2], encoded_shape[3], encoded_shape[4],), name='Encoded')\n","y = encoded_input\n","y = Flatten()(y)\n","y = Dense(32,activation='selu')(y)\n","y = Dense(16,activation='selu')(y)\n","class_pred = Dense(2,activation='softmax')(y)\n","\n","classifier = Model(encoded_input,class_pred,name='classifier')\n","\n","classifier.summary()"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Model: \"classifier\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoded (InputLayer)         [(None, 15, 20, 2, 40)]   0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 24000)             0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 32)                768032    \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 16)                528       \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 2)                 34        \n","=================================================================\n","Total params: 768,594\n","Trainable params: 768,594\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjQVyVdYzQ-4","colab_type":"code","outputId":"768a7853-5f00-4cf5-dbde-11642b6346ca","executionInfo":{"status":"ok","timestamp":1589312011753,"user_tz":240,"elapsed":4982,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["ICAE_autoencoder = Model(inputs=input_img,\n","                  outputs=[decoder(encoder(input_img)),classifier(encoder(input_img))],\n","                   name='ICAE_autoencoder')\n","ICAE_autoencoder.summary()"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Model: \"ICAE_autoencoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input (InputLayer)              [(None, 120, 160, 16 0                                            \n","__________________________________________________________________________________________________\n","ICAE_encoder (Model)            (None, 15, 20, 2, 40 11560       Input[0][0]                      \n","                                                                 Input[0][0]                      \n","__________________________________________________________________________________________________\n","ICAE_decoder (Model)            (None, 120, 160, 16, 23561       ICAE_encoder[1][0]               \n","__________________________________________________________________________________________________\n","classifier (Model)              (None, 2)            768594      ICAE_encoder[2][0]               \n","==================================================================================================\n","Total params: 803,715\n","Trainable params: 803,715\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WzIAsNitzQ-7","colab_type":"code","colab":{}},"source":["losses = {\"ICAE_decoder\":'mse','classifier':'categorical_crossentropy'}\n","metrics= {\"ICAE_decoder\":'mae','classifier':['acc',tf.keras.metrics.Precision()]}\n","loss_weights={\"ICAE_decoder\":0.5,'classifier':0.5}\n","\n","ICAE_autoencoder.compile(optimizer='sgd', \n","                         loss=losses,\n","                         loss_weights = loss_weights,\n","                         metrics=metrics)\n","\n","#ICAE_hist = ICAE_autoencoder.fit(x_train, x_train, epochs=1, verbose=1, \\\n","#                                 validation_data=(x_test, x_test)) # epochs=200\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aonFiMErCkN3","colab_type":"code","colab":{}},"source":["train_generator = MyDataGenerator(train_list,processed_dir,to_fit=True,augment=False,batch_size=32)\n","test_generator = MyDataGenerator(test_list,processed_dir,batch_size=32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xq404p3hmDdZ","colab_type":"code","outputId":"dc4c6f36-4cc7-4f2d-d803-3b00fb3d166c","executionInfo":{"status":"error","timestamp":1589252223073,"user_tz":240,"elapsed":1087476,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["history=ICAE_autoencoder.fit_generator(generator=train_generator,epochs=10,\n","                                       validation_data=test_generator,shuffle=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"," 7/24 [=======>......................] - ETA: 2:58 - loss: 1.6104 - ICAE_decoder_loss: 0.0823 - classifier_loss: 0.6313 - ICAE_decoder_mae: 0.2237 - classifier_acc: 0.6518 - classifier_precision_1: 0.6518"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppgSLdmM89c3","colab_type":"code","colab":{}},"source":["test_generator = MyDataGenerator(test_list,processed_dir,batch_size=16,to_fit=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"luWUKWBj9BbH","colab_type":"code","colab":{}},"source":["pred = ICAE_autoencoder.predict_generator(test_generator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDeDerZN9IC-","colab_type":"code","colab":{}},"source":["np.sum(np.round(pred[1]),axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zgPYRR_9hch","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}