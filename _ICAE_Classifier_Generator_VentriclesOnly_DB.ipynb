{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":" ICAE_Classifier_Generator_VentriclesOnly_DB.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Xt2onyB1zQ9Z","colab_type":"code","colab":{}},"source":["%matplotlib inline \n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from sklearn.utils import class_weight"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8ug2tfPzWqa","colab_type":"code","outputId":"8b400574-c79b-49a1-96f9-430ea7803661","executionInfo":{"status":"ok","timestamp":1589304723090,"user_tz":240,"elapsed":23873,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vXKe3JlXzQ9d","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IT-I0pU4zQ9g","colab_type":"code","outputId":"98b959a7-343b-41b6-8ff9-a1a2a0be7296","executionInfo":{"status":"ok","timestamp":1589302694409,"user_tz":240,"elapsed":2266,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","print('Tensorflow version:', tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tensorflow version: 2.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nPFgeYTuzQ9k","colab_type":"text"},"source":["#### Create Train/Test Subset"]},{"cell_type":"code","metadata":{"id":"qYrPlrRqzQ9k","colab_type":"code","outputId":"fafba911-8b92-46df-ae4a-3c5b135476a6","executionInfo":{"status":"ok","timestamp":1589304727564,"user_tz":240,"elapsed":1091,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["%cd /content/drive/My Drive/AD_MRI\n","import pickle\n","import pandas as pd\n","with open('AD_MRI_Master','rb') as f:\n","    master_list = pickle.load(f)\n","    \n","master_sheet = pd.DataFrame.from_dict(master_list, orient='index')\n","display(master_sheet.head())\n","\n","from sklearn.model_selection import train_test_split\n","\n","train_list,test_list,train_label,test_label = train_test_split(master_sheet.subject.values,\n","                                                               master_sheet.diagnosis.values\n","                                                               ,random_state = 1337,test_size=0.2)\n","\n","\n","AD_count = 0\n","for lab in train_label:\n","    if lab == 'AD':\n","        AD_count +=1\n","\n","print('train_ratio AD: ',AD_count/len(train_label))\n","\n","AD_count = 0\n","for lab in test_label:\n","    if lab == 'AD':\n","        AD_count +=1\n","print('test_ratio AD: ',AD_count/len(test_label))\n","#ratios are the same, we're good to go. \n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/AD_MRI\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>subject</th>\n","      <th>age</th>\n","      <th>diagnosis</th>\n","      <th>scan_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>OAS30001</th>\n","      <td>OAS30001</td>\n","      <td>65.0</td>\n","      <td>CN</td>\n","      <td>OAS30001_MR_d0129</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30002</th>\n","      <td>OAS30002</td>\n","      <td>68.0</td>\n","      <td>CN</td>\n","      <td>OAS30002_MR_d0371</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30003</th>\n","      <td>OAS30003</td>\n","      <td>60.0</td>\n","      <td>CN</td>\n","      <td>OAS30003_MR_d0558</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30004</th>\n","      <td>OAS30004</td>\n","      <td>58.0</td>\n","      <td>CN</td>\n","      <td>OAS30004_MR_d1101</td>\n","    </tr>\n","    <tr>\n","      <th>OAS30005</th>\n","      <td>OAS30005</td>\n","      <td>48.0</td>\n","      <td>CN</td>\n","      <td>OAS30005_MR_d0143</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           subject   age diagnosis            scan_ID\n","OAS30001  OAS30001  65.0        CN  OAS30001_MR_d0129\n","OAS30002  OAS30002  68.0        CN  OAS30002_MR_d0371\n","OAS30003  OAS30003  60.0        CN  OAS30003_MR_d0558\n","OAS30004  OAS30004  58.0        CN  OAS30004_MR_d1101\n","OAS30005  OAS30005  48.0        CN  OAS30005_MR_d0143"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["train_ratio AD:  0.36862244897959184\n","test_ratio AD:  0.3622448979591837\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWz1F457zQ9r","colab_type":"text"},"source":["### Create Generator"]},{"cell_type":"code","metadata":{"id":"Q3IK5qfYzQ9r","colab_type":"code","colab":{}},"source":["processed_dir = '/content/drive/My Drive/AD_MRI/PROCESSED/'\n","\n","# custom data generator.\n","import random\n","import scipy\n","import numpy as np\n","import cv2\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","import random\n","\n","import scipy\n","\n","def labels_to_categorical(labels):\n","    le = LabelEncoder()\n","    le.fit([\"CN\", \"AD\"])\n","    num_lab=to_categorical(le.transform(labels),num_classes=2)\n","    return num_lab\n","\n","\n","\n","class MyDataGenerator(Sequence):\n","    \"\"\"Generates data for Keras\n","    Sequence based data generator. Suitable for building data generator for training and prediction.\n","    \"\"\"\n","    def __init__(self, list_IDs, processed_dir,augment=False, \n","                 to_fit=True, batch_size=32, dim=(120, 160, 120, 1),\n","                 n_classes=2, shuffle=True, ventricals_only = True):\n","        \"\"\"Initialization\n","        :param list_IDs: list of all 'label' PATHS\n","        :param labels: list of image labels ***MUST ALREADY BE (N X 2) ARRAY***\n","        :param image_path: path to images location\n","        # \n","        :param to_fit: True to return X and y, False to return X only\n","        :param batch_size: batch size at each iteration\n","        :param dim: tuple indicating image dimension\n","        :param n_channels: number of image channels\n","        :param n_classes: number of output masks\n","        :param shuffle: True to shuffle label indexes after every epoch\n","        \"\"\"\n","        self.list_IDs = list_IDs\n","        self.processed_dir = processed_dir\n","        #self.labels = labels\n","        self.augment = augment\n","        self.ventricals_only = ventricals_only\n","        #self.image_path = image_path not needed\n","        #self.mask_path = mask_path   not needed\n","        self.to_fit = to_fit\n","        self.batch_size = batch_size\n","        self.dim = dim\n","        #self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\n","        :return: number of batches per epoch\n","        \"\"\"\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        \"\"\"Generate one batch of data\n","        :param index: index of the batch\n","        :return: X and y when fitting. X only when predicting\n","        \"\"\"\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # Generate data\n","        X,y = self._load_data(list_IDs_temp)\n","        X=np.float32(X)\n","        if self.ventricals_only:\n","          X = X[:,:,:,50:66,:]\n","        if self.to_fit:\n","            y= {'classifier':y,'ICAE_decoder':X}\n","            return X,y\n","        else:\n","            return X\n","\n","    def on_epoch_end(self):\n","        \"\"\"Updates indexes after each epoch\n","        \"\"\"\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def _load_data(self, list_IDs_temp):\n","        \"\"\"Generates data containing batch_size images\n","        :param list_IDs_temp: list of label ids to load\n","        :return: batch of images\n","        \"\"\"\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim))\n","        y = np.empty((self.batch_size,self.n_classes), dtype=int)\n","        \n","        \n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            #start X\n","            with open(self.processed_dir+ID+'_data','rb') as f:\n","                data = pickle.load(f)\n","                \n","            \n","            x_reshape= np.reshape(data['image'], (120, 160, 120, 1) )\n","            if self.augment == True:\n","                x_reshape = scipy.ndimage.rotate(x_reshape, \n","                                           axes=random.choice([(0,1),(0,2),(1,2)]),\n","                                           angle=random.choice([360-15,15]),\n","                                           reshape=False)\n","            X[i,] = x_reshape\n","            \n","            #start y\n","            y[i,] = labels_to_categorical([data['diagnosis']])\n","            \n","            \n","\n","        return X,y\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpzZF63uzQ9w","colab_type":"code","colab":{}},"source":["processed_dir = '/content/drive/My Drive/AD_MRI/PROCESSED/'\n","mdg= MyDataGenerator(test_list,processed_dir,to_fit=True,augment=True,batch_size=2)\n","\n","X,pred=mdg.__getitem__(0)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUEOTwa87Kwl","colab_type":"code","outputId":"90cdf204-a5e9-48eb-b1fc-a54545687158","executionInfo":{"status":"ok","timestamp":1589304414058,"user_tz":240,"elapsed":990,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 120, 160, 15, 1)"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"RHJs-MSozQ92","colab_type":"text"},"source":["##### --- Start adaptation from Arezoo's notebook ---"]},{"cell_type":"code","metadata":{"id":"-u8_nKai0tPP","colab_type":"code","outputId":"dbb472fb-8a34-4391-b339-3ffad4557b8b","executionInfo":{"status":"error","timestamp":1589303638795,"user_tz":240,"elapsed":918,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":304}},"source":["import matplotlib.pyplot as plt\n","axs,fig = plt.subplot(5,4,1)\n","for i in range(20):\n","\n","  plt.imshow(X[0,:,:,55+i,0])\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-524f71b9b57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'AxesSubplot' object is not iterable"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAGwAAABICAYAAAATWxDtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAADXklEQVR4nO2cPWsUURSGn9cEFVIoqIWoEAUxpLDQRa1sbDRFUmgRGxUiEsQfINjZ2IuCBBG1UdEqFiKCgo1GE/ATUaIgRgQ1Qko/4FjsoCFkMzeTmY0nngcWZnbm3vvCw8ycvctcmRmBHxbNd4BgdoQwZ4QwZ4QwZ4QwZ4QwZ+QKk3RB0mdJL5oRKJiZlCvsIrC74hxBIrnCzOw+8K0JWYIEWsvqSNIR4AhAW1vb1o6OjrK6XnCMjIx8NbNVRdqWJszMBoABgFqtZsPDw2V1veCQ9L5o26gSnRHCnJFS1l8BHgCbJI1J6qs+VtCI3GeYme1vRpAgjbglOiOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSOEOSNJmKTdkl5LGpV0vOpQQWNS3g9rAc4Ce4BOYL+kzqqDBdOTcoVtA0bN7J2Z/QCuAj3VxgoakfJS+hrgw6T9MWD71JMmryIAfP/HFmJZCXyd7xCT2FS0YSWrCEgaNrNaWX3PlX8xT9G2KbfEj8C6Sftrs++CeSBF2GNgo6T1khYDvcBgtbGCRqS8lP5L0jHgNtACXDCzlznNBsoIVyILJo9ikWZfxEyHM0KYMwoLy5uukrRE0rXs+JCk9rkELSnTIUlfJD3JPocrzjPj4qCqczrL+0zSltxOzWzWH+rFx1tgA7AYeAp0TjnnKHAu2+4FrhUZq+RMh4AzVeaYMt5OYAvwosHxLuAWIGAHMJTXZ9ErLGW6qge4lG3fAHZJUsHxysrUVBIWB+0BLludh8BySatn6rOosOmmq9Y0OsfMfgETwIqC45WVCWBvdvu5IWndNMebSWrmP/xvRcdNoN3MNgN3+HsHcENRYSnTVX/OkdQKLAPGC45XSiYzGzez79nueWBrhXlSmPW0X1FhKdNVg8DBbHsfcNeq/ZWem2nK86EbeFVhnhQGgQNZtbgDmDCzTzO2mEMF1AW8oV6Znci+Owl0Z9tLgevAKPAI2NCEqiwv0yngJfUK8h7QUXGeK8An4Cf151Mf0A/0Z8dF/c/ht8BzoJbXZ0xNOeN/KzrcE8KcEcKcEcKcEcKcEcKcEcKc8RsqGLHB0l7O/QAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"pf0QJqFOzQ-a","colab_type":"text"},"source":["#### Building Encoder"]},{"cell_type":"code","metadata":{"id":"NQHRA3MVzQ-b","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv3D, MaxPool3D, Dropout, \\\n","    Flatten, Conv3DTranspose, UpSampling3D, Reshape\n","from tensorflow.keras.layers import Input\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ayyv4uXRzQ-d","colab_type":"code","outputId":"75953aff-8383-44eb-f039-4d9ccced8542","executionInfo":{"status":"ok","timestamp":1589249125448,"user_tz":240,"elapsed":1839,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"source":["input_img = Input(shape=(120, 160, 120 , 1), name='Input')\n","\n","print('\\ninput shape:', input_img.shape)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(input_img)\n","x = MaxPool3D((2,2,2), name='MaxPooling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = MaxPool3D((2,2,2), name='MaxPooling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_3')(x)\n","x = MaxPool3D((2,2,2), name='MaxPooling_3')(x)\n","x = Dropout(0.8, name='DropOut_3')(x)\n","\n","conv_shape = K.int_shape(x)\n","\n","print('shape after convolutions:', conv_shape)\n","\n","# x = Flatten(name='Flatten')(x)\n","\n","# x = Dense(32, activation='selu', name='SELU_1')(x)\n","# x = Dense(16, activation='selu', name='SELU_2')(x)\n","\n","# encoded = Dense(2, name='Encoded')(x)\n","\n","# encoded_shape = K.int_shape(encoded)\n","\n","# print('final encoded shape:', encoded_shape, '\\n')\n","\n","encoded = x\n","encoded_shape = K.int_shape(encoded)\n","\n","\n","encoder = Model(input_img, encoded, name='CAE_encoder')\n","encoder.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 120, 160, 120, 1)\n","shape after convolutions: (None, 15, 20, 15, 10)\n","Model: \"CAE_encoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input (InputLayer)           [(None, 120, 160, 120, 1) 0         \n","_________________________________________________________________\n","Convolution_1 (Conv3D)       (None, 120, 160, 120, 10) 280       \n","_________________________________________________________________\n","MaxPooling_1 (MaxPooling3D)  (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","DropOut_1 (Dropout)          (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","Convolution_2 (Conv3D)       (None, 60, 80, 60, 10)    2710      \n","_________________________________________________________________\n","MaxPooling_2 (MaxPooling3D)  (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","DropOut_2 (Dropout)          (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","Convolution_3 (Conv3D)       (None, 30, 40, 30, 10)    2710      \n","_________________________________________________________________\n","MaxPooling_3 (MaxPooling3D)  (None, 15, 20, 15, 10)    0         \n","_________________________________________________________________\n","DropOut_3 (Dropout)          (None, 15, 20, 15, 10)    0         \n","=================================================================\n","Total params: 5,700\n","Trainable params: 5,700\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxKAey2vzQ-f","colab_type":"code","colab":{}},"source":["# model only: post-encoder\n","\n","# x = Flatten(name='Flatten')(x)\n","\n","# x = Dense(32, activation='selu', name='SELU_1')(x)\n","# x = Dense(16, activation='selu', name='SELU_2')(x)\n","\n","# encoded = Dense(2, name='Encoded')(x)\n","\n","# encoded_shape = K.int_shape(encoded)\n","\n","# print('final encoded shape:', encoded_shape, '\\n')\n","\n","# encoder = Model(input_img, encoded, name='CAE_encoder')\n","# encoder.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XoHcBk7SzQ-h","colab_type":"text"},"source":["##### CAE Encoder layers\n","\n","Input\n","\n","    120 x 160 x 120 x 1\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    120 x 160 x 120 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30 x 40 x 30 x 10\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    30 x 40 x 30 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    15 x 20 x 15 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    15 x 20 x 15 x 10\n","    \n","\n","<!-- ###### In the Classifier only:\n","\n","Flatten\n","\n","    45000\n","\n","Dense layer (32 channels, SELU activation)\n","\n","    32\n","\n","Dense layer (16 channels, SELU activation)\n","\n","    16\n","\n","Dense layer (2 possible outputs)\n","\n","    2\n"," -->"]},{"cell_type":"markdown","metadata":{"id":"b1o-Xo2SzQ-h","colab_type":"text"},"source":["#### Building Decoder"]},{"cell_type":"code","metadata":{"id":"KiVNE5H4yPaU","colab_type":"code","outputId":"e56ae292-4f52-4d95-d1db-6f1a6e85894a","executionInfo":{"status":"ok","timestamp":1589249125450,"user_tz":240,"elapsed":1830,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoded_shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 15, 20, 15, 10)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"NnPBrgD6zQ-i","colab_type":"code","outputId":"0f20d4f2-6685-4592-841a-bb769a8d046b","executionInfo":{"status":"ok","timestamp":1589249125658,"user_tz":240,"elapsed":2032,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["encoded_input = Input(shape=(encoded_shape[1],encoded_shape[2], encoded_shape[3], encoded_shape[4],), name='Encoded')\n","\n","x = encoded_input\n","\n","print('\\ninput shape:', encoded_input.shape)\n","\n","# x = Dense(16, activation='selu', name='SELU_2')(encoded_input)\n","# x = Dense(32, activation='selu', name='SELU_1')(x)\n","# x = Dense(np.prod(conv_shape[1:]), name='Product')(x)\n","# x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3], conv_shape[4]), name='Reshape')(x)\n","\n","# print('shape after reshape:', K.int_shape(x))\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_3')(x)\n","x = UpSampling3D((2,2,2), name='UpSampling_3')(x)\n","x = Dropout(0.8, name='DropOut_3')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = UpSampling3D((2,2,2), name='UpSampling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(x)\n","x = UpSampling3D((2,2,2), name='UpSampling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","# decoded = Dense(1, activation='sigmoid', name='Output')(x)\n","decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same', name='Output')(x)\n","\n","print('final decoded shape:', K.int_shape(decoded), '\\n')\n","\n","decoder = Model(encoded_input, decoded, name='CAE_decoder')\n","decoder.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 15, 20, 15, 10)\n","final decoded shape: (None, 120, 160, 120, 1) \n","\n","Model: \"CAE_decoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoded (InputLayer)         [(None, 15, 20, 15, 10)]  0         \n","_________________________________________________________________\n","Convolution_3 (Conv3DTranspo (None, 15, 20, 15, 10)    2710      \n","_________________________________________________________________\n","UpSampling_3 (UpSampling3D)  (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","DropOut_3 (Dropout)          (None, 30, 40, 30, 10)    0         \n","_________________________________________________________________\n","Convolution_2 (Conv3DTranspo (None, 30, 40, 30, 10)    2710      \n","_________________________________________________________________\n","UpSampling_2 (UpSampling3D)  (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","DropOut_2 (Dropout)          (None, 60, 80, 60, 10)    0         \n","_________________________________________________________________\n","Convolution_1 (Conv3DTranspo (None, 60, 80, 60, 10)    2710      \n","_________________________________________________________________\n","UpSampling_1 (UpSampling3D)  (None, 120, 160, 120, 10) 0         \n","_________________________________________________________________\n","DropOut_1 (Dropout)          (None, 120, 160, 120, 10) 0         \n","_________________________________________________________________\n","Output (Conv3DTranspose)     (None, 120, 160, 120, 1)  271       \n","=================================================================\n","Total params: 8,401\n","Trainable params: 8,401\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZAaPqPwezQ-k","colab_type":"text"},"source":["<!-- \n"," ###### In the Classifier only:\n","\n","\n","Input\n","\n","    2\n","\n","Dense layer (16 channels, SELU activation)\n","\n","    16\n","\n","Dense layer (32 channels, SELU activation)\n","\n","    32\n","\n","Dense layer (product of encoded_shape dimensions 15x20x15x10)\n","\n","    45000\n","\n","Reshape to encoded_shape dimensions\n","\n","    15 x 20 x 15 x 10 \n","    \n","     -->\n","##### CAE Decoder layers\n","\n","Input\n","\n","    15 x 20 x 15 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    15 x 20 x 15 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30x 40 x 30 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    30 x 40 x 30 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    120 x 160 x 120 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    120 x 160 x 120 x 10\n","\n","Convolutional transpose layer (1 channel, 3x3x3 kernel, sigmoid activation, padding)\n","\n","    120 x 160 x 120 x 1\n"]},{"cell_type":"markdown","metadata":{"id":"V3szdqC1zQ-k","colab_type":"text"},"source":["#### Building Autoencoder"]},{"cell_type":"code","metadata":{"id":"QKb0jdkXzQ-m","colab_type":"code","outputId":"d3e899f9-1372-4137-e84c-937bc6553563","executionInfo":{"status":"ok","timestamp":1589249125659,"user_tz":240,"elapsed":2028,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["autoencoder = Model(input_img, decoder(encoder(input_img)), name='CAE_autoencoder')\n","autoencoder.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"CAE_autoencoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input (InputLayer)           [(None, 120, 160, 120, 1) 0         \n","_________________________________________________________________\n","CAE_encoder (Model)          (None, 15, 20, 15, 10)    5700      \n","_________________________________________________________________\n","CAE_decoder (Model)          (None, 120, 160, 120, 1)  8401      \n","=================================================================\n","Total params: 14,101\n","Trainable params: 14,101\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wKlx4vFKzQ-o","colab_type":"code","colab":{}},"source":["autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","#hist = autoencoder.fit(x_train, x_train, epochs=1, verbose=1, validation_data=(x_test, x_test)) # epochs=200"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NdI_IT8bzQ-r","colab_type":"text"},"source":["##### --- End adaption from Arezoo's notebook ---"]},{"cell_type":"markdown","metadata":{"id":"ZpFLNADNzQ-r","colab_type":"text"},"source":["### ICAE Inception Model"]},{"cell_type":"markdown","metadata":{"id":"I9if6blZzQ-s","colab_type":"text"},"source":["#### Building Encoder"]},{"cell_type":"code","metadata":{"id":"1_5StYluzQ-s","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import TensorBoard\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv3D, MaxPool3D, Dropout, Flatten, \\\n","    Conv3DTranspose, UpSampling3D, Reshape\n","from tensorflow.keras.layers import Input\n","\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.regularizers import l1_l2\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGFALorfzQ-v","colab_type":"code","colab":{}},"source":["def inception_module(input, filter_operation):\n","    \"\"\"\n","    filter_operation is a list of inception operations for:\n","        1x1x1 kernel, \n","        1x1x1 then 3x3x3 kernels, \n","        1x1x1 then 3x3x3 then 3x3x3 kernels, \n","        and 3x3x3 maxpooling then 1x1x1 kernels, \n","            respectively.\n","    \"\"\"\n","    \n","    # According to Nature paper (Oh et. al.), l1 and l2 values of 10e-4 performed the best \n","    #   from experimentation with 0.01, 0.001, 0.0001, 0.00001 values.\n","    l1_value = 10e-4\n","    l2_value = 10e-4\n","\n","    # Branch A\n","    branch_1x1x1 = Conv3D(filter_operation[0], kernel_size=(1, 1, 1), activation='relu', \\\n","                          padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                          name='Branch_A_1x1x1')(input)\n","\n","    # Branch B\n","    branch_3x3x3_initial = Conv3D(filter_operation[1], kernel_size=(1, 1, 1), activation='relu', \\\n","                                  padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                  name='Branch_B_1x1x1')(input)\n","    branch_3x3x3 = Conv3D(filter_operation[1], kernel_size=(3, 3, 3), activation='relu', \\\n","                          padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                          name='Branch_B_3x3x3')(branch_3x3x3_initial)\n","\n","    # Branch C\n","    branch_double_3x3x3_initial = Conv3D(filter_operation[2], kernel_size=(1, 1, 1), \\\n","                                         activation='relu', padding='same', \\\n","                                         kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                         name='Branch_C_1x1x1')(input)\n","    branch_double_3x3x3_middle = Conv3D(filter_operation[2], kernel_size=(3, 3, 3), \\\n","                                        activation='relu', padding='same', \\\n","                                        kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                        name='Branch_C_1st_3x3x3')(branch_double_3x3x3_initial)\n","    branch_double_3x3x3 = Conv3D(filter_operation[2], kernel_size=(3, 3, 3), activation='relu', \\\n","                                 padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                 name='Branch_C_2nd_3x3x3')(branch_double_3x3x3_middle)\n","\n","    # Branch D\n","    branch_maxpool_3x3x3_initial = MaxPool3D(pool_size=(3, 3, 3), strides=(1, 1, 1), \\\n","                                             padding='same', name='Branch_D_3x3x3_maxpool')(input)\n","    branch_maxpool_3x3x3 = Conv3D(filter_operation[3], kernel_size=(1, 1, 1), activation='relu', \\\n","                                  padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n","                                  name='Branch_D_1x1x1')(branch_maxpool_3x3x3_initial)\n","    \n","    # Merge branches\n","    modules = [branch_1x1x1, branch_3x3x3, branch_double_3x3x3, branch_maxpool_3x3x3]\n","    merged_module = concatenate(modules, name='Inception_Merged') # axis=-1\n","    \n","    return merged_module\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HX5sfPuTzQ-x","colab_type":"code","outputId":"e20f0bb9-2dcd-4f8d-fb29-bd50a1d34db6","executionInfo":{"status":"ok","timestamp":1589305668025,"user_tz":240,"elapsed":1005,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["input_img = Input(shape= (120, 160, 16 , 1), name='Input')\n","\n","print('\\ninput shape:', input_img.shape)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(input_img)\n","x = MaxPool3D((2,2,2), name='MaxPooling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = MaxPool3D((2,2,2), name='MaxPooling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","# filter_operations = [40, 40, 40, 40]\n","filter_operations = [10, 10, 10, 10]\n","\n","x = inception_module(x, filter_operations)\n","x = MaxPool3D((2,2,2), name='Inception_MaxPooling')(x)\n","encoded = Dropout(0.8, name='DropOut_3')(x)\n","\n","# print('shape after inception:', K.int_shape(x))\n","\n","# ## for model only\n","# encoded = Flatten(name='Flatten')(encoded)\n","# encoded = Dense(1, activation='sigmoid', name='Prediction')(encoded)\n","# ##\n","\n","encoder = Model(input_img, encoded, name='ICAE_encoder')\n","\n","encoded_shape = K.int_shape(encoded)\n","print('final encoded shape:', encoded_shape, '\\n')\n","\n","encoder.summary(positions=[.35, .64, .71, 1.]) # adjusts print settings to minimize truncation\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 120, 160, 16, 1)\n","final encoded shape: (None, 15, 20, 2, 40) \n","\n","Model: \"ICAE_encoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                      Output Shape                Param  Connected to                 \n","==================================================================================================\n","Input (InputLayer)                [(None, 120, 160, 16, 1)]   0                                   \n","__________________________________________________________________________________________________\n","Convolution_1 (Conv3D)            (None, 120, 160, 16, 10)    280    Input[0][0]                  \n","__________________________________________________________________________________________________\n","MaxPooling_1 (MaxPooling3D)       (None, 60, 80, 8, 10)       0      Convolution_1[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_1 (Dropout)               (None, 60, 80, 8, 10)       0      MaxPooling_1[0][0]           \n","__________________________________________________________________________________________________\n","Convolution_2 (Conv3D)            (None, 60, 80, 8, 10)       2710   DropOut_1[0][0]              \n","__________________________________________________________________________________________________\n","MaxPooling_2 (MaxPooling3D)       (None, 30, 40, 4, 10)       0      Convolution_2[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_2 (Dropout)               (None, 30, 40, 4, 10)       0      MaxPooling_2[0][0]           \n","__________________________________________________________________________________________________\n","Branch_C_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_B_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_C_1st_3x3x3 (Conv3D)       (None, 30, 40, 4, 10)       2710   Branch_C_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_D_3x3x3_maxpool (MaxPoolin (None, 30, 40, 4, 10)       0      DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_A_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Branch_B_3x3x3 (Conv3D)           (None, 30, 40, 4, 10)       2710   Branch_B_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_C_2nd_3x3x3 (Conv3D)       (None, 30, 40, 4, 10)       2710   Branch_C_1st_3x3x3[0][0]     \n","__________________________________________________________________________________________________\n","Branch_D_1x1x1 (Conv3D)           (None, 30, 40, 4, 10)       110    Branch_D_3x3x3_maxpool[0][0] \n","__________________________________________________________________________________________________\n","Inception_Merged (Concatenate)    (None, 30, 40, 4, 40)       0      Branch_A_1x1x1[0][0]         \n","                                                                     Branch_B_3x3x3[0][0]         \n","                                                                     Branch_C_2nd_3x3x3[0][0]     \n","                                                                     Branch_D_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Inception_MaxPooling (MaxPooling3 (None, 15, 20, 2, 40)       0      Inception_Merged[0][0]       \n","__________________________________________________________________________________________________\n","DropOut_3 (Dropout)               (None, 15, 20, 2, 40)       0      Inception_MaxPooling[0][0]   \n","==================================================================================================\n","Total params: 11,560\n","Trainable params: 11,560\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xXTWo7y5zQ-z","colab_type":"text"},"source":["##### ICAE Encoder layers\n","\n","Input\n","\n","    120 x 160 x 120 x 1\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    120 x 160 x 120 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30 x 40 x 30 x 10\n","\n","Inception branched layers\n","\n","    A: 30 x 40 x 30 x 10\n","\n","    B: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n","\n","    C: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n","\n","    D: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n","\n","Inception merged layer\n","\n","    30 x 40 x 30 x 40\n","\n","Maxpooling downsample (2x2x2 kernel)\n","\n","    15 x 20 x 15 x 40\n","\n","Dense layer (2 possible outputs, SoftMax activation)\n","\n","    15 x 20 x 15 x 2\n"]},{"cell_type":"markdown","metadata":{"id":"KsOlxg4vzQ-z","colab_type":"text"},"source":["#### Building Decoder"]},{"cell_type":"code","metadata":{"id":"AyLnMo4szQ-0","colab_type":"code","outputId":"c5633c2d-9348-4e3f-bd0d-3c63473a5246","executionInfo":{"status":"ok","timestamp":1589305669315,"user_tz":240,"elapsed":773,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["encoded_input= Input(shape=(encoded_shape[1],encoded_shape[2], \\\n","                            encoded_shape[3], encoded_shape[4],), name='Input')\n","\n","print('\\ninput shape:', encoded_input.shape)\n","\n","filter_operations = [40, 40, 40, 40]\n","filter_operations = [10, 10, 10, 10]\n","combined_dim = sum(filter_operations) # taken from encoder\n","\n","x = Dense(combined_dim, activation='selu', name='SELU')(encoded_input)\n","\n","### ************\n","x = encoded_input\n","x = inception_module(x, filter_operations)\n","### ************\n","# print('shape after inception:', K.int_shape(x))\n","\n","x = UpSampling3D((2,2,2), name='Inception_Upsampling')(x)\n","x = Dropout(0.8, name='DropOut_3')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n","x = UpSampling3D((2,2,2), name='Upsampling_2')(x)\n","x = Dropout(0.8, name='DropOut_2')(x)\n","\n","x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(x)\n","x = UpSampling3D((2,2,2), name='Upsampling_1')(x)\n","x = Dropout(0.8, name='DropOut_1')(x)\n","\n","# decoded = Dense(1, activation='sigmoid', name='Output')(x)\n","decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same', name='Output')(x)\n","\n","print('final decoded shape:', K.int_shape(decoded), '\\n')\n","\n","decoder = Model(encoded_input, decoded, name='ICAE_decoder')\n","decoder.summary(positions=[.35, .64, .71, 1.])\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["\n","input shape: (None, 15, 20, 2, 40)\n","final decoded shape: (None, 120, 160, 16, 1) \n","\n","Model: \"ICAE_decoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                      Output Shape                Param  Connected to                 \n","==================================================================================================\n","Input (InputLayer)                [(None, 15, 20, 2, 40)]     0                                   \n","__________________________________________________________________________________________________\n","Branch_C_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_B_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_C_1st_3x3x3 (Conv3D)       (None, 15, 20, 2, 10)       2710   Branch_C_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_D_3x3x3_maxpool (MaxPoolin (None, 15, 20, 2, 40)       0      Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_A_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Input[0][0]                  \n","__________________________________________________________________________________________________\n","Branch_B_3x3x3 (Conv3D)           (None, 15, 20, 2, 10)       2710   Branch_B_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Branch_C_2nd_3x3x3 (Conv3D)       (None, 15, 20, 2, 10)       2710   Branch_C_1st_3x3x3[0][0]     \n","__________________________________________________________________________________________________\n","Branch_D_1x1x1 (Conv3D)           (None, 15, 20, 2, 10)       410    Branch_D_3x3x3_maxpool[0][0] \n","__________________________________________________________________________________________________\n","Inception_Merged (Concatenate)    (None, 15, 20, 2, 40)       0      Branch_A_1x1x1[0][0]         \n","                                                                     Branch_B_3x3x3[0][0]         \n","                                                                     Branch_C_2nd_3x3x3[0][0]     \n","                                                                     Branch_D_1x1x1[0][0]         \n","__________________________________________________________________________________________________\n","Inception_Upsampling (UpSampling3 (None, 30, 40, 4, 40)       0      Inception_Merged[0][0]       \n","__________________________________________________________________________________________________\n","DropOut_3 (Dropout)               (None, 30, 40, 4, 40)       0      Inception_Upsampling[0][0]   \n","__________________________________________________________________________________________________\n","Convolution_2 (Conv3DTranspose)   (None, 30, 40, 4, 10)       10810  DropOut_3[0][0]              \n","__________________________________________________________________________________________________\n","Upsampling_2 (UpSampling3D)       (None, 60, 80, 8, 10)       0      Convolution_2[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_2 (Dropout)               (None, 60, 80, 8, 10)       0      Upsampling_2[0][0]           \n","__________________________________________________________________________________________________\n","Convolution_1 (Conv3DTranspose)   (None, 60, 80, 8, 10)       2710   DropOut_2[0][0]              \n","__________________________________________________________________________________________________\n","Upsampling_1 (UpSampling3D)       (None, 120, 160, 16, 10)    0      Convolution_1[0][0]          \n","__________________________________________________________________________________________________\n","DropOut_1 (Dropout)               (None, 120, 160, 16, 10)    0      Upsampling_1[0][0]           \n","__________________________________________________________________________________________________\n","Output (Conv3DTranspose)          (None, 120, 160, 16, 1)     271    DropOut_1[0][0]              \n","==================================================================================================\n","Total params: 23,561\n","Trainable params: 23,561\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"opGBnug7zQ-3","colab_type":"text"},"source":["##### ICAE Decoder layers\n","\n","Input\n","\n","    15 x 20 x 15 x 10\n","\n","Inception branched layers\n","\n","    A: 15 x 20 x 15 x 10\n","\n","    B: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n","\n","    C: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n","\n","    D: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    30 x 40 x 30 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    30x 40 x 30 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    30 x 40 x 30 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    60 x 80 x 60 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    60 x 80 x 60 x 10\n","\n","Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n","\n","    60 x 80 x 60 x 10\n","\n","Upsampling (2x2x2 kernel)\n","\n","    120 x 160 x 120 x 10\n","\n","Dropout (80% of nodes set to 0)\n","\n","    120 x 160 x 120 x 10\n","\n","Convolutional transpose layer (1 channel, 3x3x3 kernel, sigmoid activation, padding)\n","\n","    120 x 160 x 120 x 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ol-4Dt7WzQ-4","colab_type":"text"},"source":["#### Building Autoencoder"]},{"cell_type":"code","metadata":{"id":"5xQYaVA2ssdV","colab_type":"code","outputId":"f2e93db8-0526-44f7-dcfe-bce027723de9","executionInfo":{"status":"ok","timestamp":1589305671015,"user_tz":240,"elapsed":1538,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["#classifier\n","\n","encoded_input = Input(shape=(encoded_shape[1],encoded_shape[2], encoded_shape[3], encoded_shape[4],), name='Encoded')\n","y = encoded_input\n","y = Flatten()(y)\n","y = Dropout(0.5)(y)\n","y = Dense(32,activation='selu')(y)\n","y = Dropout(0.5)(y)\n","y = Dense(16,activation='selu')(y)\n","class_pred = Dense(2,activation='softmax')(y)\n","\n","classifier = Model(encoded_input,class_pred,name='classifier')\n","\n","classifier.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"classifier\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoded (InputLayer)         [(None, 15, 20, 2, 40)]   0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 24000)             0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 24000)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 32)                768032    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 16)                528       \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 34        \n","=================================================================\n","Total params: 768,594\n","Trainable params: 768,594\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjQVyVdYzQ-4","colab_type":"code","outputId":"6d67768d-24b3-4e7c-e31a-dcd22b3d247e","executionInfo":{"status":"ok","timestamp":1589305673658,"user_tz":240,"elapsed":1349,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["ICAE_autoencoder = Model(inputs=input_img,\n","                  outputs=[decoder(encoder(input_img)),classifier(encoder(input_img))],\n","                   name='ICAE_autoencoder')\n","ICAE_autoencoder.summary()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Model: \"ICAE_autoencoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input (InputLayer)              [(None, 120, 160, 16 0                                            \n","__________________________________________________________________________________________________\n","ICAE_encoder (Model)            (None, 15, 20, 2, 40 11560       Input[0][0]                      \n","                                                                 Input[0][0]                      \n","__________________________________________________________________________________________________\n","ICAE_decoder (Model)            (None, 120, 160, 16, 23561       ICAE_encoder[1][0]               \n","__________________________________________________________________________________________________\n","classifier (Model)              (None, 2)            768594      ICAE_encoder[2][0]               \n","==================================================================================================\n","Total params: 803,715\n","Trainable params: 803,715\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WzIAsNitzQ-7","colab_type":"code","colab":{}},"source":["losses = {\"ICAE_decoder\":'mse','classifier':'categorical_crossentropy'}\n","metrics= {\"ICAE_decoder\":'mae','classifier':'acc'}\n","loss_weights={\"ICAE_decoder\":0.5,'classifier':0.5}\n","\n","ICAE_autoencoder.compile(optimizer='sgd', \n","                         loss=losses,\n","                         loss_weights = loss_weights,\n","                         metrics=metrics)\n","\n","#ICAE_hist = ICAE_autoencoder.fit(x_train, x_train, epochs=1, verbose=1, \\\n","#                                 validation_data=(x_test, x_test)) # epochs=200\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aonFiMErCkN3","colab_type":"code","colab":{}},"source":["train_generator = MyDataGenerator(train_list,processed_dir,to_fit=True,augment=False,batch_size=16)\n","test_generator = MyDataGenerator(test_list,processed_dir,batch_size=16)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xq404p3hmDdZ","colab_type":"code","outputId":"c9a078b6-d16c-4860-980a-ff9dd95c2d5a","executionInfo":{"status":"error","timestamp":1589306195388,"user_tz":240,"elapsed":100425,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}},"colab":{"base_uri":"https://localhost:8080/","height":378}},"source":["history=ICAE_autoencoder.fit_generator(generator=train_generator,epochs=10,\n","                                       validation_data=test_generator)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"," 6/49 [==>...........................] - ETA: 6:58 - loss: 1.8250 - ICAE_decoder_loss: 0.1403 - classifier_loss: 0.6735 - ICAE_decoder_mae: 0.3266 - classifier_acc: 0.5833"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-e3f845e3d2ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history=ICAE_autoencoder.fit_generator(generator=train_generator,epochs=10,\n\u001b[0;32m----> 2\u001b[0;31m                                        validation_data=test_generator)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"2z5sOACLoioY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"outputId":"342b5e1d-364c-48e6-ec68-9b2fa0c00356"},"source":["history=ICAE_autoencoder.fit(train_generator,epochs=10, use_multiprocessing=True,\n","                                       validation_data=test_generator)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","48/49 [============================>.] - ETA: 10s - loss: 1.8061 - ICAE_decoder_loss: 0.1166 - classifier_loss: 0.6726 - ICAE_decoder_mae: 0.2955 - classifier_acc: 0.6224WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","49/49 [==============================] - ETA: 0s - loss: 1.8054 - ICAE_decoder_loss: 0.1164 - classifier_loss: 0.6717 - ICAE_decoder_mae: 0.2952 - classifier_acc: 0.6250 WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","49/49 [==============================] - 724s 15s/step - loss: 1.8054 - ICAE_decoder_loss: 0.1164 - classifier_loss: 0.6717 - ICAE_decoder_mae: 0.2952 - classifier_acc: 0.6250 - val_loss: 1.7885 - val_ICAE_decoder_loss: 0.1090 - val_classifier_loss: 0.6572 - val_ICAE_decoder_mae: 0.2853 - val_classifier_acc: 0.6406\n","Epoch 2/10\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","26/49 [==============>...............] - ETA: 2:46 - loss: 1.7949 - ICAE_decoder_loss: 0.1113 - classifier_loss: 0.6738 - ICAE_decoder_mae: 0.2874 - classifier_acc: 0.6226"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppgSLdmM89c3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"96204e03-4fb6-4b2a-da8e-86894ee5936d","executionInfo":{"status":"ok","timestamp":1589305701702,"user_tz":240,"elapsed":3470,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}}},"source":["X.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 120, 160, 16, 1)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"luWUKWBj9BbH","colab_type":"code","colab":{}},"source":["out= ICAE_autoencoder.predict(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDeDerZN9IC-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7c3f706d-8084-4a6e-de32-c8a6f934b76e","executionInfo":{"status":"ok","timestamp":1589305702843,"user_tz":240,"elapsed":987,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}}},"source":["out[0].shape"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 120, 160, 16, 1)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"hnDPdyTe9MEB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e54f72ee-a0c9-4d04-b85f-d531e583fde9","executionInfo":{"status":"ok","timestamp":1589305152457,"user_tz":240,"elapsed":1125,"user":{"displayName":"Daniel Brennan","photoUrl":"","userId":"06116736020032641541"}}},"source":[""],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 120, 160, 15, 1)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"2zgPYRR_9hch","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}