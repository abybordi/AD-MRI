{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory analysis of small subset of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_subjects','rb') as f:\n",
    "               images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of records:', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Record names:', images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First record keys:', images['OAS30001'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of MRI:', images['OAS30001']['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Value of a center voxel:', images['OAS30001']['image'][60][80][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN label\n",
    "print('Center (60th) 160x120 image of first CN MRI:')\n",
    "plt.imshow(images['OAS30001']['image'][60], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN label\n",
    "print('All 160x120 images of first CN MRI:') \n",
    "fig, axes = plt.subplots(12,10, figsize=(20,20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.imshow(images['OAS30001']['image'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AD label\n",
    "print('Center (60th) 160x120 image of first AD MRI:')\n",
    "plt.imshow(images['OAS30024']['image'][60], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AD label\n",
    "print('All 160x120 images of first AD MRI:')\n",
    "fig, axes = plt.subplots(12,10, figsize=(20,20))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.imshow(images['OAS30024']['image'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --- Start adaptation from Arezoo's notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_name_list = []\n",
    "\n",
    "for x1 in images:\n",
    "    im_name_list.append(x1)\n",
    "im_name_list\n",
    "\n",
    "# im_name_list : list of image names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = np.zeros((1, 120, 160, 120))\n",
    "for name in im_name_list:\n",
    "    pixels = np.append(pixels ,np.reshape(images[name]['image'], (1, 120, 160, 120)), axis=0)\n",
    "\n",
    "# print(pixels.shape)\n",
    "# pixels : initial zeroes row and 4D representation of images\n",
    "# input_ims : 4D representation of images\n",
    "\n",
    "input_ims = pixels[1:12, :, :, :] \n",
    "input_ims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = input_ims[0:9, :, :, :] # x_train : first 9 records\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = input_ims[9:11, :, :, :] # x_test : last 2 records\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(x_test, (2, 120, 160, 120, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [images[key]['group'] for key in images.keys()]\n",
    "y_test = y_train[-2:] # y_test : last 2 records\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:9] # y_train : first 9 records\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numeric(x):\n",
    "    if x == \"AD\":\n",
    "        return 1\n",
    "    elif x == \"CN\":\n",
    "        return 0\n",
    "    else:\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(map(convert_numeric, y_train))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(map(convert_numeric, y_test))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking into first image\n",
    "first_im = images['OAS30001']\n",
    "first = first_im['image']\n",
    "first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "balancing_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "balancing_weights = dict(enumerate(balancing_weights))\n",
    "balancing_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_modified = np.reshape(first, (120, 160, 120, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (9, 120, 160, 120, 1))\n",
    "x_test = np.reshape(x_test, (2, 120, 160, 120, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train, (9, 1))\n",
    "y_test = np.reshape(y_test, (2, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv3D, MaxPool3D, Dropout, \\\n",
    "    Flatten, Conv3DTranspose, UpSampling3D, Reshape\n",
    "from tensorflow.keras.layers import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(120, 160, 120 , 1), name='Input')\n",
    "\n",
    "print('\\ninput shape:', input_img.shape)\n",
    "\n",
    "x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(input_img)\n",
    "x = MaxPool3D((2,2,2), name='MaxPooling_1')(x)\n",
    "x = Dropout(0.8, name='DropOut_1')(x)\n",
    "\n",
    "x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n",
    "x = MaxPool3D((2,2,2), name='MaxPooling_2')(x)\n",
    "x = Dropout(0.8, name='DropOut_2')(x)\n",
    "\n",
    "x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_3')(x)\n",
    "x = MaxPool3D((2,2,2), name='MaxPooling_3')(x)\n",
    "x = Dropout(0.8, name='DropOut_3')(x)\n",
    "\n",
    "conv_shape = K.int_shape(x)\n",
    "\n",
    "print('shape after convolutions:', conv_shape)\n",
    "\n",
    "# x = Flatten(name='Flatten')(x)\n",
    "\n",
    "# x = Dense(32, activation='selu', name='SELU_1')(x)\n",
    "# x = Dense(16, activation='selu', name='SELU_2')(x)\n",
    "\n",
    "# encoded = Dense(2, name='Encoded')(x)\n",
    "\n",
    "# encoded_shape = K.int_shape(encoded)\n",
    "\n",
    "# print('final encoded shape:', encoded_shape, '\\n')\n",
    "\n",
    "encoded = x\n",
    "encoded_shape = K.int_shape(encoded)\n",
    "\n",
    "\n",
    "encoder = Model(input_img, encoded, name='CAE_encoder')\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model only: post-encoder\n",
    "\n",
    "# x = Flatten(name='Flatten')(x)\n",
    "\n",
    "# x = Dense(32, activation='selu', name='SELU_1')(x)\n",
    "# x = Dense(16, activation='selu', name='SELU_2')(x)\n",
    "\n",
    "# encoded = Dense(2, name='Encoded')(x)\n",
    "\n",
    "# encoded_shape = K.int_shape(encoded)\n",
    "\n",
    "# print('final encoded shape:', encoded_shape, '\\n')\n",
    "\n",
    "# encoder = Model(input_img, encoded, name='CAE_encoder')\n",
    "# encoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CAE Encoder layers\n",
    "\n",
    "Input\n",
    "\n",
    "    120 x 160 x 120 x 1\n",
    "\n",
    "Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    120 x 160 x 120 x 10\n",
    "\n",
    "Maxpooling downsample (2x2x2 kernel)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Maxpooling downsample (2x2x2 kernel)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Maxpooling downsample (2x2x2 kernel)\n",
    "\n",
    "    15 x 20 x 15 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    15 x 20 x 15 x 10\n",
    "    \n",
    "\n",
    "<!-- ###### In the Classifier only:\n",
    "\n",
    "Flatten\n",
    "\n",
    "    45000\n",
    "\n",
    "Dense layer (32 channels, SELU activation)\n",
    "\n",
    "    32\n",
    "\n",
    "Dense layer (16 channels, SELU activation)\n",
    "\n",
    "    16\n",
    "\n",
    "Dense layer (2 possible outputs)\n",
    "\n",
    "    2\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoded_shape[1],encoded_shape[2], encoded_shape[3], encoded_shape[4],), name='Encoded')\n",
    "\n",
    "x = encoded_input\n",
    "\n",
    "print('\\ninput shape:', encoded_input.shape)\n",
    "\n",
    "# x = Dense(16, activation='selu', name='SELU_2')(encoded_input)\n",
    "# x = Dense(32, activation='selu', name='SELU_1')(x)\n",
    "# x = Dense(np.prod(conv_shape[1:]), name='Product')(x)\n",
    "# x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3], conv_shape[4]), name='Reshape')(x)\n",
    "\n",
    "# print('shape after reshape:', K.int_shape(x))\n",
    "\n",
    "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_3')(x)\n",
    "x = UpSampling3D((2,2,2), name='UpSampling_3')(x)\n",
    "x = Dropout(0.8, name='DropOut_3')(x)\n",
    "\n",
    "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n",
    "x = UpSampling3D((2,2,2), name='UpSampling_2')(x)\n",
    "x = Dropout(0.8, name='DropOut_2')(x)\n",
    "\n",
    "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(x)\n",
    "x = UpSampling3D((2,2,2), name='UpSampling_1')(x)\n",
    "x = Dropout(0.8, name='DropOut_1')(x)\n",
    "\n",
    "# decoded = Dense(1, activation='sigmoid', name='Output')(x)\n",
    "decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same', name='Output')(x)\n",
    "\n",
    "print('final decoded shape:', K.int_shape(decoded), '\\n')\n",
    "\n",
    "decoder = Model(encoded_input, decoded, name='CAE_decoder')\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    " ###### In the Classifier only:\n",
    "\n",
    "\n",
    "Input\n",
    "\n",
    "    2\n",
    "\n",
    "Dense layer (16 channels, SELU activation)\n",
    "\n",
    "    16\n",
    "\n",
    "Dense layer (32 channels, SELU activation)\n",
    "\n",
    "    32\n",
    "\n",
    "Dense layer (product of encoded_shape dimensions 15x20x15x10)\n",
    "\n",
    "    45000\n",
    "\n",
    "Reshape to encoded_shape dimensions\n",
    "\n",
    "    15 x 20 x 15 x 10 \n",
    "    \n",
    "     -->\n",
    "##### CAE Decoder layers\n",
    "\n",
    "Input\n",
    "\n",
    "    15 x 20 x 15 x 10\n",
    "\n",
    "Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    15 x 20 x 15 x 10\n",
    "\n",
    "Upsampling (2x2x2 kernel)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    30x 40 x 30 x 10\n",
    "\n",
    "Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Upsampling (2x2x2 kernel)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Upsampling (2x2x2 kernel)\n",
    "\n",
    "    120 x 160 x 120 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    120 x 160 x 120 x 10\n",
    "\n",
    "Convolutional transpose layer (1 channel, 3x3x3 kernel, sigmoid activation, padding)\n",
    "\n",
    "    120 x 160 x 120 x 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoder(encoder(input_img)), name='CAE_autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "hist = autoencoder.fit(x_train, x_train, epochs=1, verbose=1, validation_data=(x_test, x_test)) # epochs=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --- End adaption from Arezoo's notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICAE Inception Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv3D, MaxPool3D, Dropout, Flatten, \\\n",
    "    Conv3DTranspose, UpSampling3D, Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.regularizers import l1_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(input, filter_operation):\n",
    "    \"\"\"\n",
    "    filter_operation is a list of inception operations for:\n",
    "        1x1x1 kernel, \n",
    "        1x1x1 then 3x3x3 kernels, \n",
    "        1x1x1 then 3x3x3 then 3x3x3 kernels, \n",
    "        and 3x3x3 maxpooling then 1x1x1 kernels, \n",
    "            respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    # According to Nature paper (Oh et. al.), l1 and l2 values of 10e-4 performed the best \n",
    "    #   from experimentation with 0.01, 0.001, 0.0001, 0.00001 values.\n",
    "    l1_value = 10e-4\n",
    "    l2_value = 10e-4\n",
    "\n",
    "    # Branch A\n",
    "    branch_1x1x1 = Conv3D(filter_operation[0], kernel_size=(1, 1, 1), activation='relu', \\\n",
    "                          padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                          name='Branch_A_1x1x1')(input)\n",
    "\n",
    "    # Branch B\n",
    "    branch_3x3x3_initial = Conv3D(filter_operation[1], kernel_size=(1, 1, 1), activation='relu', \\\n",
    "                                  padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                                  name='Branch_B_1x1x1')(input)\n",
    "    branch_3x3x3 = Conv3D(filter_operation[1], kernel_size=(3, 3, 3), activation='relu', \\\n",
    "                          padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                          name='Branch_B_3x3x3')(branch_3x3x3_initial)\n",
    "\n",
    "    # Branch C\n",
    "    branch_double_3x3x3_initial = Conv3D(filter_operation[2], kernel_size=(1, 1, 1), \\\n",
    "                                         activation='relu', padding='same', \\\n",
    "                                         kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                                         name='Branch_C_1x1x1')(input)\n",
    "    branch_double_3x3x3_middle = Conv3D(filter_operation[2], kernel_size=(3, 3, 3), \\\n",
    "                                        activation='relu', padding='same', \\\n",
    "                                        kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                                        name='Branch_C_1st_3x3x3')(branch_double_3x3x3_initial)\n",
    "    branch_double_3x3x3 = Conv3D(filter_operation[2], kernel_size=(3, 3, 3), activation='relu', \\\n",
    "                                 padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                                 name='Branch_C_2nd_3x3x3')(branch_double_3x3x3_middle)\n",
    "\n",
    "    # Branch D\n",
    "    branch_maxpool_3x3x3_initial = MaxPool3D(pool_size=(3, 3, 3), strides=(1, 1, 1), \\\n",
    "                                             padding='same', name='Branch_D_3x3x3_maxpool')(input)\n",
    "    branch_maxpool_3x3x3 = Conv3D(filter_operation[3], kernel_size=(1, 1, 1), activation='relu', \\\n",
    "                                  padding='same', kernel_regularizer=l1_l2(l1_value, l2_value), \\\n",
    "                                  name='Branch_D_1x1x1')(branch_maxpool_3x3x3_initial)\n",
    "    \n",
    "    # Merge branches\n",
    "    modules = [branch_1x1x1, branch_3x3x3, branch_double_3x3x3, branch_maxpool_3x3x3]\n",
    "    merged_module = concatenate(modules, name='Inception_Merged') # axis=-1\n",
    "    \n",
    "    return merged_module\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape= (120, 160, 120 , 1), name='Input')\n",
    "\n",
    "print('\\ninput shape:', input_img.shape)\n",
    "\n",
    "x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(input_img)\n",
    "x = MaxPool3D((2,2,2), name='MaxPooling_1')(x)\n",
    "x = Dropout(0.8, name='DropOut_1')(x)\n",
    "\n",
    "x = Conv3D(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n",
    "x = MaxPool3D((2,2,2), name='MaxPooling_2')(x)\n",
    "x = Dropout(0.8, name='DropOut_2')(x)\n",
    "\n",
    "# filter_operations = [40, 40, 40, 40]\n",
    "filter_operations = [10, 10, 10, 10]\n",
    "\n",
    "x = inception_module(x, filter_operations)\n",
    "x = MaxPool3D((2,2,2), name='Inception_MaxPooling')(x)\n",
    "encoded = Dropout(0.8, name='DropOut_3')(x)\n",
    "\n",
    "# print('shape after inception:', K.int_shape(x))\n",
    "\n",
    "# ## for model only\n",
    "# encoded = Flatten(name='Flatten')(encoded)\n",
    "# encoded = Dense(1, activation='sigmoid', name='Prediction')(encoded)\n",
    "# ##\n",
    "\n",
    "encoder = Model(input_img, encoded, name='ICAE_encoder')\n",
    "\n",
    "encoded_shape = K.int_shape(encoded)\n",
    "print('final encoded shape:', encoded_shape, '\\n')\n",
    "\n",
    "encoder.summary(positions=[.35, .64, .71, 1.]) # adjusts print settings to minimize truncation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ICAE Encoder layers\n",
    "\n",
    "Input\n",
    "\n",
    "    120 x 160 x 120 x 1\n",
    "\n",
    "Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    120 x 160 x 120 x 10\n",
    "\n",
    "Maxpooling downsample (2x2x2 kernel)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Convolutional layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Maxpooling downsample (2x2x2 kernel)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Inception branched layers\n",
    "\n",
    "    A: 30 x 40 x 30 x 10\n",
    "\n",
    "    B: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n",
    "\n",
    "    C: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n",
    "\n",
    "    D: 30 x 40 x 30 x 10  ->  30 x 40 x 30 x 10\n",
    "\n",
    "Inception merged layer\n",
    "\n",
    "    30 x 40 x 30 x 40\n",
    "\n",
    "Maxpooling downsample (2x2x2 kernel)\n",
    "\n",
    "    15 x 20 x 15 x 40\n",
    "\n",
    "Dense layer (2 possible outputs, SoftMax activation)\n",
    "\n",
    "    15 x 20 x 15 x 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input= Input(shape=(encoded_shape[1],encoded_shape[2], \\\n",
    "                            encoded_shape[3], encoded_shape[4],), name='Input')\n",
    "\n",
    "print('\\ninput shape:', encoded_input.shape)\n",
    "\n",
    "# filter_operations = [40, 40, 40, 40]\n",
    "# filter_operations = [10, 10, 10, 10]\n",
    "combined_dim = sum(filter_operations) # taken from encoder\n",
    "\n",
    "# x = Dense(combined_dim, activation='selu', name='SELU')(encoded_input)\n",
    "\n",
    "x = encoded_input\n",
    "\n",
    "x = inception_module(x, filter_operations)\n",
    "\n",
    "# print('shape after inception:', K.int_shape(x))\n",
    "\n",
    "x = UpSampling3D((2,2,2), name='Inception_Upsampling')(x)\n",
    "x = Dropout(0.8, name='DropOut_3')(x)\n",
    "\n",
    "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_2')(x)\n",
    "x = UpSampling3D((2,2,2), name='Upsampling_2')(x)\n",
    "x = Dropout(0.8, name='DropOut_2')(x)\n",
    "\n",
    "x = Conv3DTranspose(10, (3,3,3), activation='relu', padding='same', name='Convolution_1')(x)\n",
    "x = UpSampling3D((2,2,2), name='Upsampling_1')(x)\n",
    "x = Dropout(0.8, name='DropOut_1')(x)\n",
    "\n",
    "# decoded = Dense(1, activation='sigmoid', name='Output')(x)\n",
    "decoded = Conv3DTranspose(1, (3,3,3), activation='sigmoid', padding='same', name='Output')(x)\n",
    "\n",
    "print('final decoded shape:', K.int_shape(decoded), '\\n')\n",
    "\n",
    "decoder = Model(encoded_input, decoded, name='ICAE_decoder')\n",
    "decoder.summary(positions=[.35, .64, .71, 1.])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ICAE Decoder layers\n",
    "\n",
    "Input\n",
    "\n",
    "    15 x 20 x 15 x 10\n",
    "\n",
    "Inception branched layers\n",
    "\n",
    "    A: 15 x 20 x 15 x 10\n",
    "\n",
    "    B: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n",
    "\n",
    "    C: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n",
    "\n",
    "    D: 15 x 20 x 15 x 10  ->  15 x 20 x 15 x 10\n",
    "\n",
    "Upsampling (2x2x2 kernel)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    30x 40 x 30 x 10\n",
    "\n",
    "Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    30 x 40 x 30 x 10\n",
    "\n",
    "Upsampling (2x2x2 kernel)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Convolutional transpose layer (10 channels, 3x3x3 kernel, ReLU activation, padding)\n",
    "\n",
    "    60 x 80 x 60 x 10\n",
    "\n",
    "Upsampling (2x2x2 kernel)\n",
    "\n",
    "    120 x 160 x 120 x 10\n",
    "\n",
    "Dropout (80% of nodes set to 0)\n",
    "\n",
    "    120 x 160 x 120 x 10\n",
    "\n",
    "Convolutional transpose layer (1 channel, 3x3x3 kernel, sigmoid activation, padding)\n",
    "\n",
    "    120 x 160 x 120 x 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICAE_autoencoder = Model(input_img, decoder(encoder(input_img)), name='ICAE_autoencoder')\n",
    "ICAE_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICAE_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "ICAE_hist = ICAE_autoencoder.fit(x_train, x_train, epochs=1, verbose=1, \\\n",
    "                                 validation_data=(x_test, x_test)) # epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (standard)",
   "language": "python",
   "name": "standard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
